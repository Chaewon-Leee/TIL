{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":2279,"status":"ok","timestamp":1674012730036,"user":{"displayName":"강사","userId":"16181995035441534154"},"user_tz":-540},"id":"dW0Ct36DcqJ5","outputId":"59e8093d-2ed3-4285-fed0-41a6133620b5"},"outputs":[{"name":"stdout","output_type":"stream","text":["cpu\n"]}],"source":["from multiclass_functions1 import *\n","import torch\n","from torch import nn, optim\n","import torch.nn.functional as F\n","from torchvision import datasets, transforms\n","import matplotlib.pyplot as plt\n","import numpy as np\n","DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n","print(DEVICE)"]},{"cell_type":"code","execution_count":2,"metadata":{"executionInfo":{"elapsed":5,"status":"ok","timestamp":1674012730036,"user":{"displayName":"강사","userId":"16181995035441534154"},"user_tz":-540},"id":"vfN_ffAFEqJc"},"outputs":[],"source":["# for random seed\n","import random\n","random_seed = 0\n","torch.manual_seed(random_seed)\n","torch.cuda.manual_seed(random_seed)\n","torch.cuda.manual_seed_all(random_seed) # if use multi-GPU\n","torch.backends.cudnn.deterministic = True\n","torch.backends.cudnn.benchmark = False\n","np.random.seed(random_seed)\n","random.seed(random_seed)"]},{"cell_type":"code","execution_count":3,"metadata":{"executionInfo":{"elapsed":3,"status":"ok","timestamp":1674012730036,"user":{"displayName":"강사","userId":"16181995035441534154"},"user_tz":-540},"id":"hO7KyY-2-YHx"},"outputs":[],"source":["# BATCH_SIZE = 256\n","# LR = 1e-3\n","BATCH_SIZE = 32\n","LR = 1e-3\n","EPOCH = 100\n","criterion = nn.CrossEntropyLoss()\n","NoB = 10\n","NoC = 1\n","NoBat = 5\n","activation = \"NoSigmoid\" # NO는 Batch Nomalize 여부\n","new_model_train = False\n","model_type = f\"{activation}{NoB}C{NoC}\""]},{"cell_type":"code","execution_count":4,"metadata":{"executionInfo":{"elapsed":4,"status":"ok","timestamp":1674012730037,"user":{"displayName":"강사","userId":"16181995035441534154"},"user_tz":-540},"id":"7Yk2wsyg6R4g"},"outputs":[],"source":["transform = transforms.ToTensor()\n","train_DS = datasets.MNIST(root = '../data', train=True, download=True, transform=transform)\n","test_DS = datasets.MNIST(root = '../data', train=False, download=True, transform=transform)\n","train_DL = torch.utils.data.DataLoader(train_DS, batch_size=BATCH_SIZE, shuffle=True)\n","test_DL = torch.utils.data.DataLoader(test_DS, batch_size=BATCH_SIZE, shuffle=True)"]},{"cell_type":"code","execution_count":14,"metadata":{"executionInfo":{"elapsed":14,"status":"ok","timestamp":1674012730492,"user":{"displayName":"강사","userId":"16181995035441534154"},"user_tz":-540},"id":"Bs_G7RrH-aqp"},"outputs":[],"source":["# bias = True 면 ReLU 도 잘 안된다. 일단 bias=False로 변경\n","in_channel = 1\n","# in_channel = 3\n","class CNN(nn.Module):\n","    def __init__(self):\n","        super().__init__()\n","        if activation == \"NoSigmoid\":\n","            self.conv_block = nn.Sequential(\n","                nn.Conv2d(in_channel,NoC,3, bias=False, padding=1),\n","                nn.Sigmoid(),\n","                *[i for j in range(NoB-1) for i in [nn.Conv2d(NoC,NoC,3, bias=False, padding=1), nn.Sigmoid()]]\n","                )\n","        elif activation == \"BNSigmoid\":\n","            self.conv_block = nn.Sequential(\n","                nn.Conv2d(in_channel,NoC,3, bias=False, padding=1),\n","                nn.BatchNorm2d(NoC), ## Activation 전에 놓기 = 데이터에 적용하기\n","                nn.Sigmoid(),\n","                *[i for j in range(NoB-1) for i in [nn.Conv2d(NoC,NoC,3, bias=False, padding=1), nn.BatchNorm2d(NoC), nn.Sigmoid()]]\n","                )\n","        elif activation == \"NoReLU\":\n","            self.conv_block = nn.Sequential(\n","                nn.Conv2d(in_channel,NoC,3, bias=False, padding=1),\n","                nn.ReLU(),\n","                *[i for j in range(NoB-1) for i in [nn.Conv2d(NoC,NoC,3, bias=False, padding=1), nn.ReLU()]]\n","                )\n","        elif activation == \"BNReLU\":\n","            self.conv_block = nn.Sequential(\n","                nn.Conv2d(in_channel,NoC,3, bias=False, padding=1),\n","                nn.BatchNorm2d(NoC),\n","                nn.ReLU(),\n","                *[i for j in range(NoB-1) for i in [nn.Conv2d(NoC,NoC,3, bias=False, padding=1), nn.BatchNorm2d(NoC), nn.ReLU()]]\n","                )\n","        # self.fc = nn.Linear(NoC*(28-2*NoB)*(28-2*NoB),10, bias=False)\n","        self.maxpool1 = nn.MaxPool2d(2)\n","        self.maxpool2 = nn.MaxPool2d(2)\n","        self.fc = nn.Linear(NoC*7*7,10, bias=False)\n","        # self.fc = nn.Linear(NoC*8*8,10, bias=False)\n","\n","    def forward(self, x):\n","        self.befAct=[]\n","        for layer in self.conv_block:\n","            if isinstance(layer, nn.ReLU) or isinstance(layer, nn.Sigmoid): # Activation일 경우\n","              # isinstance(1, int)\n","                with torch.no_grad():\n","                    self.befAct += [torch.flatten(x).detach().cpu()] # befAct : Activation 통과 전 데이터의 분포를 담도록\n","                    # 보기에는 그냥 데이터 값 담는 것 같은데...\n","                    # 어떠한 구간에 몇 개의 데이터를 지니고 있는지 히스토그램으로 나타낼 것이다\n","                x = layer(x)\n","            else:\n","                x = layer(x)\n","\n","        x = self.maxpool1(x)\n","        x = self.maxpool2(x)\n","        x = torch.flatten(x, start_dim=1)\n","        x = self.fc(x)\n","        return x"]},{"cell_type":"code","execution_count":15,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":12,"status":"ok","timestamp":1674012730492,"user":{"displayName":"강사","userId":"16181995035441534154"},"user_tz":-540},"id":"2Y8vs0yn99fg","outputId":"5c3d5666-6bfc-4299-cd27-c59f68d1651c"},"outputs":[{"name":"stdout","output_type":"stream","text":["CNN(\n","  (conv_block): Sequential(\n","    (0): Conv2d(1, 1, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","    (1): Sigmoid()\n","    (2): Conv2d(1, 1, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","    (3): Sigmoid()\n","    (4): Conv2d(1, 1, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","    (5): Sigmoid()\n","    (6): Conv2d(1, 1, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","    (7): Sigmoid()\n","    (8): Conv2d(1, 1, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","    (9): Sigmoid()\n","    (10): Conv2d(1, 1, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","    (11): Sigmoid()\n","    (12): Conv2d(1, 1, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","    (13): Sigmoid()\n","    (14): Conv2d(1, 1, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","    (15): Sigmoid()\n","    (16): Conv2d(1, 1, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","    (17): Sigmoid()\n","    (18): Conv2d(1, 1, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","    (19): Sigmoid()\n","  )\n","  (maxpool1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n","  (maxpool2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n","  (fc): Linear(in_features=49, out_features=10, bias=False)\n",")\n","torch.Size([32, 10])\n"]}],"source":["model=CNN().to(DEVICE)\n","print(model)\n","x_batch, _ = next(iter(train_DL))\n","print(model(x_batch.to(DEVICE)).shape)"]},{"cell_type":"code","execution_count":5,"metadata":{"executionInfo":{"elapsed":7,"status":"ok","timestamp":1674012730492,"user":{"displayName":"강사","userId":"16181995035441534154"},"user_tz":-540},"id":"At747zl19_gm"},"outputs":[],"source":["def fmap_gen(model, train_DL, idx=5):\n","    # 각 layer를 지나갈 때마다 어떤 이미지의 형태로 변화하는지 확인하기 위함\n","    x_batch, _ = next(iter(train_DL))\n","    im_data = torch.unsqueeze(x_batch[idx], dim=0).to(DEVICE)\n","    feature_map=[]\n","    x = im_data\n","    model.eval()\n","    with torch.no_grad():\n","        for layer in model.conv_block:\n","            if isinstance(layer, nn.ReLU) or isinstance(layer, nn.Sigmoid):\n","                feature_map += [x.detach().squeeze().cpu()]\n","                # 테스트 단계에서 activateion을 들어가기 전 데이터들을 모아놓음\n","                x = layer(x)\n","            else:\n","                x = layer(x)\n","    return feature_map\n","\n","def Train(model, train_DL, criterion):\n","    optimizer = optim.Adam(model.parameters(), lr=LR)\n","\n","    loss_history=[]\n","    acc_history=[]\n","    befAct_history=[]\n","    fmap_history=[]\n","\n","    NoT=len(train_DL.dataset) # The number of training data\n","\n","    for ep in range(EPOCH):\n","        rloss = 0 # running loss\n","        rcorrect = 0 # running correct\n","        befAct_e=[]\n","        # fmap\n","        fmap_history += [fmap_gen(model, train_DL)]\n","        model.train() # train mode로 전환\n","        for i, (x_batch, y_batch) in enumerate(train_DL):\n","            x_batch = x_batch.to(DEVICE)\n","            y_batch = y_batch.to(DEVICE)\n","            # inference\n","            y_hat = model(x_batch)\n","            # before activation\n","            if i < NoBat:\n","                befAct_e += [model.befAct]\n","            # loss\n","            loss = criterion(y_hat, y_batch)\n","            # update\n","            optimizer.zero_grad()\n","            loss.backward()\n","            optimizer.step()\n","            # loss accumulation\n","            loss_b = loss.item() * x_batch.shape[0]\n","            rloss += loss_b\n","            # accuracy accumulation\n","            pred = y_hat.argmax(dim=1)\n","            corrects_b = torch.sum(pred == y_batch).item()\n","            rcorrect += corrects_b\n","        # print loss\n","        loss_e = rloss/NoT\n","        accuracy_e = rcorrect/NoT * 100\n","        loss_history += [loss_e]\n","        acc_history += [accuracy_e]\n","        befAct_history += [befAct_e]\n","        print(f\"Epoch: {ep+1}, train loss: {round(loss_e,3)}, train accuracy: {round(accuracy_e,1)} %\")\n","        print(\"-\"*20)\n","\n","    return loss_history, acc_history, befAct_history, fmap_history"]},{"cell_type":"code","execution_count":17,"metadata":{"executionInfo":{"elapsed":5,"status":"ok","timestamp":1674012730492,"user":{"displayName":"강사","userId":"16181995035441534154"},"user_tz":-540},"id":"MezOlWokJyri"},"outputs":[],"source":["if new_model_train:\n","    loss_history, acc_history, befAct_history, fmap_history = Train(model, train_DL, criterion)"]},{"cell_type":"code","execution_count":18,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":37627,"status":"ok","timestamp":1674012768115,"user":{"displayName":"강사","userId":"16181995035441534154"},"user_tz":-540},"id":"cBsh5GTm-d-X","outputId":"1f9a0361-017e-4632-9e49-4859099ecf34"},"outputs":[{"name":"stdout","output_type":"stream","text":["Test accuracy: 1135/10000 (11.3 %)\n","Test accuracy: 9437/10000 (94.4 %)\n"]}],"source":["if activation[2:] == \"ReLU\":\n","    act = \"NoReLU\"\n","elif activation[2:] == \"Sigmoid\":\n","    act = \"NoSigmoid\"\n","model_type = f\"{act}{NoB}C{NoC}\"\n","\n","test_acc_No = Test(model, test_DL)\n","\n","if activation[2:] == \"ReLU\":\n","    act = \"BNReLU\"\n","elif activation[2:] == \"Sigmoid\":\n","    act = \"BNSigmoid\"\n","model_type = f\"{act}{NoB}C{NoC}\"\n","test_acc_BN = Test(model, test_DL)"]},{"cell_type":"code","execution_count":19,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":14,"status":"ok","timestamp":1674012768115,"user":{"displayName":"강사","userId":"16181995035441534154"},"user_tz":-540},"id":"-Y2uHlkVXNM_","outputId":"31ff82c4-e06a-4a67-c30f-d42901fc8d73"},"outputs":[{"name":"stdout","output_type":"stream","text":["tensor([0.7034])\n","tensor([-0.8660])\n","--------------------\n","tensor([0.7678])\n","tensor([-0.1713])\n","--------------------\n","tensor([1.0240])\n","tensor([-0.2730])\n","--------------------\n","tensor([1.8532])\n","tensor([-0.7914])\n","--------------------\n","tensor([4.0370])\n","tensor([-2.0524])\n","--------------------\n","tensor([2.4948])\n","tensor([0.7477])\n","--------------------\n","tensor([2.3084])\n","tensor([1.2031])\n","--------------------\n","tensor([1.9797])\n","tensor([-2.0637])\n","--------------------\n","tensor([1.5177])\n","tensor([-1.8384])\n","--------------------\n","tensor([1.5358])\n","tensor([-1.8825])\n","--------------------\n"]}],"source":["for layer in model.conv_block:\n","    if isinstance(layer, nn.BatchNorm2d):\n","        print(layer.weight.detach().cpu()) # nomalize 분산\n","        print(layer.bias.detach().cpu()) # nomalize 평균\n","        print(\"-\"*20)"]},{"cell_type":"markdown","metadata":{},"source":["# 결과 확인"]},{"cell_type":"markdown","metadata":{},"source":["<img src=\"image/sigmoid.png\" width=\"800\">"]},{"cell_type":"markdown","metadata":{},"source":["sigmoid\n","- BN를 안했을 때(상단)와 했을 때 비교(하단)\n","- 각 배치별로 데이터 분포를 그린 것, 색상은 0을 기준으로 양수 음수 표현한 것\n","  - 각 분포 하나가 배치 하나의 분포를 나타낸 것\n","- 아래 BN을 했을 때, 더 옹기종기 모여있는 모습\n","- layer별로 어떤 이미지가 나오는지 확인 가능\n","\n","마지막 layer만 봤을 때 분포가 오른쪽으로 오는 것으로 볼 수 있다\n","- 이미지를 봐도 위에는 제대로 안 나옴"]},{"cell_type":"markdown","metadata":{},"source":["<img src=\"image/sigmoid_NoBN_data.png\" width=\"800\">\n","<img src=\"image/sigmoid_BN_data.png\" width=\"800\">"]},{"cell_type":"markdown","metadata":{},"source":["데이터 분포들도 계속 gradient가 사라지는 것을 볼 수 있다\n","- 자꾸 왼쪽이나 오른쪽으로 치우쳐져서"]},{"cell_type":"markdown","metadata":{},"source":["<img src=\"image/RELU.png\" width=\"800\">"]},{"cell_type":"markdown","metadata":{},"source":["RELU\n","- BN이 있나 (하단) 없나 (상단) 별 차이가 없다"]},{"cell_type":"markdown","metadata":{},"source":["<img src=\"image/RELU_NoBN_data.png\" width=\"800\">\n","<img src=\"image/RELU_BN_data.png\" width=\"800\">"]},{"cell_type":"markdown","metadata":{},"source":["근데 BN의 파라미터 마저도 앞 레이어에 갈수록 vanishing gradient가 나오기 때문에 분포 자체가 활발하지 않은 것 보임"]}],"metadata":{"colab":{"authorship_tag":"ABX9TyMwuLA1lDXoT2p8VFK6xYeg","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.15"}},"nbformat":4,"nbformat_minor":0}
