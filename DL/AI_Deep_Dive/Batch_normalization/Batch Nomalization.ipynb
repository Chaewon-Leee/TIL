{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyMwuLA1lDXoT2p8VFK6xYeg"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":10,"metadata":{"id":"dW0Ct36DcqJ5","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1674012730036,"user_tz":-540,"elapsed":2279,"user":{"displayName":"강사","userId":"16181995035441534154"}},"outputId":"59e8093d-2ed3-4285-fed0-41a6133620b5"},"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n","cpu\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')\n","import sys\n","sys.path.append('/content/drive/MyDrive/Colab Notebooks')\n","from multiclass_functions1 import *\n","import torch\n","from torch import nn, optim\n","import torch.nn.functional as F\n","from torchvision import datasets, transforms\n","import matplotlib.pyplot as plt\n","import numpy as np\n","DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n","print(DEVICE)"]},{"cell_type":"code","source":["# for random seed\n","import random \n","random_seed = 0\n","torch.manual_seed(random_seed)\n","torch.cuda.manual_seed(random_seed)\n","torch.cuda.manual_seed_all(random_seed) # if use multi-GPU\n","torch.backends.cudnn.deterministic = True\n","torch.backends.cudnn.benchmark = False\n","np.random.seed(random_seed)\n","random.seed(random_seed)"],"metadata":{"id":"vfN_ffAFEqJc","executionInfo":{"status":"ok","timestamp":1674012730036,"user_tz":-540,"elapsed":5,"user":{"displayName":"강사","userId":"16181995035441534154"}}},"execution_count":11,"outputs":[]},{"cell_type":"code","source":["# BATCH_SIZE = 256\n","# LR = 1e-3\n","BATCH_SIZE = 32\n","LR = 1e-3\n","EPOCH = 100\n","criterion = nn.CrossEntropyLoss()\n","NoB = 10\n","NoC = 1\n","NoBat = 5\n","activation = \"NoSigmoid\"\n","new_model_train = False\n","model_type = f\"{activation}{NoB}C{NoC}\"\n","save_model_path = f\"/content/drive/MyDrive/Colab Notebooks/results/BN/{model_type}_MNIST.pt\"\n","save_video_path = f\"/content/drive/MyDrive/Colab Notebooks/results/BN/comparison_{activation[2:]}_{NoB}C{NoC}.mp4\"\n","save_video_path2 = f\"/content/drive/MyDrive/Colab Notebooks/results/BN/No{model_type[2:]}_only befAct.mp4\"\n","save_video_path3 = f\"/content/drive/MyDrive/Colab Notebooks/results/BN/BN{model_type[2:]}_only befAct.mp4\""],"metadata":{"id":"hO7KyY-2-YHx","executionInfo":{"status":"ok","timestamp":1674012730036,"user_tz":-540,"elapsed":3,"user":{"displayName":"강사","userId":"16181995035441534154"}}},"execution_count":12,"outputs":[]},{"cell_type":"code","source":["transform = transforms.ToTensor()\n","train_DS = datasets.MNIST(root = '/content/drive/MyDrive/Colab Notebooks/data', train=True, download=True, transform=transform)\n","test_DS = datasets.MNIST(root = '/content/drive/MyDrive/Colab Notebooks/data', train=False, download=True, transform=transform)\n","train_DL = torch.utils.data.DataLoader(train_DS, batch_size=BATCH_SIZE, shuffle=True)\n","test_DL = torch.utils.data.DataLoader(test_DS, batch_size=BATCH_SIZE, shuffle=True)"],"metadata":{"id":"7Yk2wsyg6R4g","executionInfo":{"status":"ok","timestamp":1674012730037,"user_tz":-540,"elapsed":4,"user":{"displayName":"강사","userId":"16181995035441534154"}}},"execution_count":13,"outputs":[]},{"cell_type":"code","source":["# bias = True 면 ReLU 도 잘 안된다. 일단 bias=False로 변경\n","in_channel = 1\n","# in_channel = 3\n","class CNN(nn.Module):\n","    def __init__(self):\n","        super().__init__()\n","        if activation == \"NoSigmoid\":\n","            self.conv_block = nn.Sequential(\n","                nn.Conv2d(in_channel,NoC,3, bias=False, padding=1),\n","                nn.Sigmoid(),\n","                *[i for j in range(NoB-1) for i in [nn.Conv2d(NoC,NoC,3, bias=False, padding=1), nn.Sigmoid()]]\n","                )\n","        elif activation == \"BNSigmoid\":\n","            self.conv_block = nn.Sequential(\n","                nn.Conv2d(in_channel,NoC,3, bias=False, padding=1),\n","                nn.BatchNorm2d(NoC),\n","                nn.Sigmoid(),\n","                *[i for j in range(NoB-1) for i in [nn.Conv2d(NoC,NoC,3, bias=False, padding=1), nn.BatchNorm2d(NoC), nn.Sigmoid()]]\n","                )\n","        elif activation == \"NoReLU\":\n","            self.conv_block = nn.Sequential(\n","                nn.Conv2d(in_channel,NoC,3, bias=False, padding=1),\n","                nn.ReLU(),\n","                *[i for j in range(NoB-1) for i in [nn.Conv2d(NoC,NoC,3, bias=False, padding=1), nn.ReLU()]]\n","                )\n","        elif activation == \"BNReLU\":\n","            self.conv_block = nn.Sequential(\n","                nn.Conv2d(in_channel,NoC,3, bias=False, padding=1),\n","                nn.BatchNorm2d(NoC),\n","                nn.ReLU(),\n","                *[i for j in range(NoB-1) for i in [nn.Conv2d(NoC,NoC,3, bias=False, padding=1), nn.BatchNorm2d(NoC), nn.ReLU()]]\n","                )\n","        # self.fc = nn.Linear(NoC*(28-2*NoB)*(28-2*NoB),10, bias=False)\n","        self.maxpool1 = nn.MaxPool2d(2)\n","        self.maxpool2 = nn.MaxPool2d(2)\n","        self.fc = nn.Linear(NoC*7*7,10, bias=False)\n","        # self.fc = nn.Linear(NoC*8*8,10, bias=False)\n","                            \n","    def forward(self, x):\n","        self.befAct=[]\n","        for layer in self.conv_block:\n","            if isinstance(layer, nn.ReLU) or isinstance(layer, nn.Sigmoid):\n","                with torch.no_grad():\n","                    self.befAct += [torch.flatten(x).detach().cpu()]\n","                x = layer(x)\n","            else:\n","                x = layer(x)\n","        \n","        x = self.maxpool1(x)\n","        x = self.maxpool2(x)\n","        x = torch.flatten(x, start_dim=1)\n","        x = self.fc(x)\n","        return x"],"metadata":{"id":"Bs_G7RrH-aqp","executionInfo":{"status":"ok","timestamp":1674012730492,"user_tz":-540,"elapsed":14,"user":{"displayName":"강사","userId":"16181995035441534154"}}},"execution_count":14,"outputs":[]},{"cell_type":"code","source":["model=CNN().to(DEVICE)\n","print(model)\n","x_batch, _ = next(iter(train_DL))\n","print(model(x_batch.to(DEVICE)).shape)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"2Y8vs0yn99fg","executionInfo":{"status":"ok","timestamp":1674012730492,"user_tz":-540,"elapsed":12,"user":{"displayName":"강사","userId":"16181995035441534154"}},"outputId":"5c3d5666-6bfc-4299-cd27-c59f68d1651c"},"execution_count":15,"outputs":[{"output_type":"stream","name":"stdout","text":["CNN(\n","  (conv_block): Sequential(\n","    (0): Conv2d(1, 1, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","    (1): Sigmoid()\n","    (2): Conv2d(1, 1, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","    (3): Sigmoid()\n","    (4): Conv2d(1, 1, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","    (5): Sigmoid()\n","    (6): Conv2d(1, 1, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","    (7): Sigmoid()\n","    (8): Conv2d(1, 1, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","    (9): Sigmoid()\n","    (10): Conv2d(1, 1, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","    (11): Sigmoid()\n","    (12): Conv2d(1, 1, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","    (13): Sigmoid()\n","    (14): Conv2d(1, 1, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","    (15): Sigmoid()\n","    (16): Conv2d(1, 1, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","    (17): Sigmoid()\n","    (18): Conv2d(1, 1, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","    (19): Sigmoid()\n","  )\n","  (maxpool1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n","  (maxpool2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n","  (fc): Linear(in_features=49, out_features=10, bias=False)\n",")\n","torch.Size([32, 10])\n"]}]},{"cell_type":"code","source":["def fmap_gen(model, train_DL, idx=5):\n","    x_batch, _ = next(iter(train_DL))\n","    im_data = torch.unsqueeze(x_batch[idx], dim=0).to(DEVICE)\n","    feature_map=[]\n","    x = im_data\n","    model.eval()\n","    with torch.no_grad():\n","        for layer in model.conv_block:\n","            if isinstance(layer, nn.ReLU) or isinstance(layer, nn.Sigmoid):\n","                feature_map += [x.detach().squeeze().cpu()]\n","                x = layer(x)\n","            else:\n","                x = layer(x)\n","    return feature_map\n","\n","def Train(model, train_DL, criterion):\n","    optimizer = optim.Adam(model.parameters(), lr=LR)\n","\n","    loss_history=[]\n","    acc_history=[]\n","    befAct_history=[]\n","    fmap_history=[]\n","\n","    NoT=len(train_DL.dataset) # The number of training data\n","\n","    for ep in range(EPOCH):\n","        rloss = 0 # running loss\n","        rcorrect = 0 # running correct\n","        befAct_e=[]\n","        # fmap\n","        fmap_history += [fmap_gen(model, train_DL)]\n","        model.train() # train mode로 전환\n","        for i, (x_batch, y_batch) in enumerate(train_DL):\n","            x_batch = x_batch.to(DEVICE)\n","            y_batch = y_batch.to(DEVICE)\n","            # inference\n","            y_hat = model(x_batch)\n","            # before activation\n","            if i < NoBat:\n","                befAct_e += [model.befAct]\n","            # loss\n","            loss = criterion(y_hat, y_batch)\n","            # update\n","            optimizer.zero_grad() # gradient 누적을 막기 위한 초기화\n","            loss.backward() # backpropagation\n","            optimizer.step() # weight update\n","            # loss accumulation\n","            loss_b = loss.item() * x_batch.shape[0] # batch loss # BATCH_SIZE를 곱하면 마지막 18개도 32개를 곱하니까..\n","            rloss += loss_b\n","            # accuracy accumulation\n","            pred = y_hat.argmax(dim=1)\n","            corrects_b = torch.sum(pred == y_batch).item()\n","            rcorrect += corrects_b\n","        # print loss\n","        loss_e = rloss/NoT # epoch loss\n","        accuracy_e = rcorrect/NoT * 100\n","        loss_history += [loss_e]\n","        acc_history += [accuracy_e]\n","        befAct_history += [befAct_e]\n","        print(f\"Epoch: {ep+1}, train loss: {round(loss_e,3)}, train accuracy: {round(accuracy_e,1)} %\")\n","        print(\"-\"*20)\n","        \n","    return loss_history, acc_history, befAct_history, fmap_history"],"metadata":{"id":"At747zl19_gm","executionInfo":{"status":"ok","timestamp":1674012730492,"user_tz":-540,"elapsed":7,"user":{"displayName":"강사","userId":"16181995035441534154"}}},"execution_count":16,"outputs":[]},{"cell_type":"code","source":["if new_model_train:\n","    loss_history, acc_history, befAct_history, fmap_history = Train(model, train_DL, criterion)\n","\n","    torch.save({\"model\":model,\n","                \"BATCH_SIZE\":BATCH_SIZE,\n","                \"LR\":LR,\n","                \"EPOCH\":EPOCH,\n","                \"NoB\":NoB,\n","                \"NoC\":NoC,\n","                \"loss_history\":loss_history,\n","                \"acc_history\":acc_history,\n","                \"befAct_history\":befAct_history,\n","                \"fmap_history\":fmap_history,\n","                \"activation\":activation}, save_model_path)"],"metadata":{"id":"MezOlWokJyri","executionInfo":{"status":"ok","timestamp":1674012730492,"user_tz":-540,"elapsed":5,"user":{"displayName":"강사","userId":"16181995035441534154"}}},"execution_count":17,"outputs":[]},{"cell_type":"code","source":["if activation[2:] == \"ReLU\":\n","    act = \"NoReLU\"\n","elif activation[2:] == \"Sigmoid\":\n","    act = \"NoSigmoid\"\n","model_type = f\"{act}{NoB}C{NoC}\"\n","save_model_path = f\"/content/drive/MyDrive/Colab Notebooks/results/BN/{model_type}_MNIST.pt\"\n","loaded=torch.load(save_model_path, map_location=\"cpu\")\n","load_model=loaded[\"model\"].to(DEVICE)\n","loss_history_No=loaded[\"loss_history\"]\n","acc_history_No=loaded[\"acc_history\"]\n","befAct_history_No=loaded[\"befAct_history\"]\n","fmap_history_No=loaded[\"fmap_history\"]\n","test_acc_No = Test(load_model, test_DL)\n","\n","if activation[2:] == \"ReLU\":\n","    act = \"BNReLU\"\n","elif activation[2:] == \"Sigmoid\":\n","    act = \"BNSigmoid\"\n","model_type = f\"{act}{NoB}C{NoC}\"\n","save_model_path = f\"/content/drive/MyDrive/Colab Notebooks/results/BN/{model_type}_MNIST.pt\"\n","loaded=torch.load(save_model_path, map_location=\"cpu\")\n","load_model=loaded[\"model\"].to(DEVICE)\n","loss_history_BN=loaded[\"loss_history\"]\n","acc_history_BN=loaded[\"acc_history\"]\n","befAct_history_BN=loaded[\"befAct_history\"]\n","fmap_history_BN=loaded[\"fmap_history\"]\n","test_acc_BN = Test(load_model, test_DL)"],"metadata":{"id":"cBsh5GTm-d-X","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1674012768115,"user_tz":-540,"elapsed":37627,"user":{"displayName":"강사","userId":"16181995035441534154"}},"outputId":"1f9a0361-017e-4632-9e49-4859099ecf34"},"execution_count":18,"outputs":[{"output_type":"stream","name":"stdout","text":["Test accuracy: 1135/10000 (11.3 %)\n","Test accuracy: 9437/10000 (94.4 %)\n"]}]},{"cell_type":"code","source":["for layer in load_model.conv_block:\n","    if isinstance(layer, nn.BatchNorm2d):\n","        print(layer.weight.detach().cpu())\n","        print(layer.bias.detach().cpu())\n","        print(\"-\"*20)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"-Y2uHlkVXNM_","executionInfo":{"status":"ok","timestamp":1674012768115,"user_tz":-540,"elapsed":14,"user":{"displayName":"강사","userId":"16181995035441534154"}},"outputId":"31ff82c4-e06a-4a67-c30f-d42901fc8d73"},"execution_count":19,"outputs":[{"output_type":"stream","name":"stdout","text":["tensor([0.7034])\n","tensor([-0.8660])\n","--------------------\n","tensor([0.7678])\n","tensor([-0.1713])\n","--------------------\n","tensor([1.0240])\n","tensor([-0.2730])\n","--------------------\n","tensor([1.8532])\n","tensor([-0.7914])\n","--------------------\n","tensor([4.0370])\n","tensor([-2.0524])\n","--------------------\n","tensor([2.4948])\n","tensor([0.7477])\n","--------------------\n","tensor([2.3084])\n","tensor([1.2031])\n","--------------------\n","tensor([1.9797])\n","tensor([-2.0637])\n","--------------------\n","tensor([1.5177])\n","tensor([-1.8384])\n","--------------------\n","tensor([1.5358])\n","tensor([-1.8825])\n","--------------------\n"]}]},{"cell_type":"code","source":["# hist_range=7\n","# def plot_hist(ax, samples, layer, hist_max):\n","#     for i in range(NoBat):\n","#         hist, bins = np.histogram(samples[i][layer], range=(-hist_range,hist_range), bins=100)\n","#         # [batch][layer]\n","#         bins = (bins[:-1] + bins[1:])/2\n","#         bins_m=bins[bins<0]\n","#         bins_p=bins[bins>0]\n","#         hist_m=hist[bins<0]\n","#         hist_p=hist[bins>0]\n","#         ax.bar(bins_m, hist_m, zs=i, zdir=\"y\", color='r', alpha=0.5, width=0.1)\n","#         ax.bar(bins_p, hist_p, zs=i, zdir=\"y\", color='g', alpha=0.5, width=0.1)\n","#     plt.xlabel(\"values\")\n","#     plt.ylabel(\"batch #\")\n","#     ax.set_xlim([-hist_range,hist_range])\n","#     ax.set_zlim([0, hist_max])\n","#     ax.view_init(elev=20,azim=-70)\n","# # %%\n","# from matplotlib.animation import FuncAnimation\n","\n","# hist_mean_max_No = torch.zeros(NoB,EPOCH)\n","# for layer in range(NoB):\n","#     for ep in range(EPOCH):\n","#         for i in range(NoBat):\n","#             hist, _ = np.histogram(befAct_history_No[ep][i][layer], range=(-hist_range,hist_range), bins=100)\n","#             max_val = max(hist)\n","#         if max_val > hist_mean_max_No[layer][ep]:\n","#             hist_mean_max_No[layer][ep] = max_val\n","# hist_mean_max_No = hist_mean_max_No.mean(dim=1)\n","        \n","# hist_mean_max_BN = torch.zeros(NoB,EPOCH)\n","# for layer in range(NoB):\n","#     for ep in range(EPOCH):\n","#         for i in range(NoBat):\n","#             hist, _ = np.histogram(befAct_history_BN[ep][i][layer], range=(-hist_range,hist_range), bins=100)\n","#             max_val = max(hist)\n","#         if max_val > hist_mean_max_BN[layer][ep]:\n","#             hist_mean_max_BN[layer][ep] = max_val\n","# hist_mean_max_BN = hist_mean_max_BN.mean(dim=1)\n","# # %%\n","# fig = plt.figure(figsize=[20,9])\n","# def animate(ep): # for 문의 i 라고 생각하면 됨\n","#     plt.clf()\n","    \n","#     plt.suptitle(f\"Epoch: {range(1,EPOCH+1)[ep]}, # of conv block = {NoB}, # of channels = {NoC}\")\n","        \n","#     ax=plt.subplot(2,6,1, projection=\"3d\")\n","#     plot_hist(ax, befAct_history_No[ep], layer=0, hist_max=hist_mean_max_No[0])\n","#     plt.title(\"first layer\")\n","    \n","#     ax=plt.subplot(2,6,2, projection=\"3d\")\n","#     plot_hist(ax, befAct_history_No[ep], layer=-1, hist_max=hist_mean_max_No[-1])\n","#     plt.title(\"last layer\")\n","    \n","#     ax1=plt.subplot(2,6,3)\n","#     ax2 = ax1.twinx()\n","#     p1=ax1.plot(range(1,EPOCH+1)[:ep+1],loss_history_No[:ep+1],'r')\n","#     p2=ax2.plot(range(1,EPOCH+1)[:ep+1],acc_history_No[:ep+1])\n","#     ax1.set_xlim([-5,EPOCH+5])\n","#     ax1.set_ylim([0.1, 2.5])\n","#     ax2.set_ylim([0, 100])\n","#     ax1.set_xlabel(\"Epochs\")\n","#     ax1.set_ylabel(\"Train Loss\")\n","#     ax2.set_ylabel(\"accuracy\")\n","#     ax1.set_title(f\"Test acc = {test_acc_No} %, BS = {BATCH_SIZE} & LR = {LR}\", fontsize=7)\n","#     ax1.grid()\n","#     plt.legend(p1+p2,[\"loss\",\"accuracy\"], loc=\"right\")\n","    \n","#     for r in range(2):\n","#         for i in range(5):\n","#             plt.subplot(4,12,7+i+12*r, xticks=[], yticks=[])\n","#             plt.imshow(fmap_history_No[ep][i+r*5], cmap=\"gray\")\n","#             plt.title(f\"layer {i+r*5}\")\n","    \n","#     ax=plt.subplot(2,6,7, projection=\"3d\")\n","#     plot_hist(ax, befAct_history_BN[ep], layer=0, hist_max=hist_mean_max_BN[0])\n","#     plt.title(\"first layer\")\n","    \n","#     ax=plt.subplot(2,6,8, projection=\"3d\")\n","#     plot_hist(ax, befAct_history_BN[ep], layer=-1, hist_max=hist_mean_max_BN[-1])\n","#     plt.title(\"last layer\")\n","    \n","#     ax1=plt.subplot(2,6,9)\n","#     ax2 = ax1.twinx()\n","#     p1=ax1.plot(range(1,EPOCH+1)[:ep+1],loss_history_BN[:ep+1],'r')\n","#     p2=ax2.plot(range(1,EPOCH+1)[:ep+1],acc_history_BN[:ep+1])\n","#     ax1.set_xlim([-5,EPOCH+5])\n","#     ax1.set_ylim([0.1, 2.5])\n","#     ax2.set_ylim([0, 100])\n","#     ax1.set_xlabel(\"Epochs\")\n","#     ax1.set_ylabel(\"Train Loss\")\n","#     ax2.set_ylabel(\"accuracy\")\n","#     ax1.set_title(f\"Test acc = {test_acc_BN} %, BS = {BATCH_SIZE} & LR = {LR}\", fontsize=7)\n","#     ax1.grid()\n","#     plt.legend(p1+p2,[\"loss\",\"accuracy\"], loc=\"right\")\n","    \n","#     for r in range(2):\n","#         for i in range(5):\n","#             plt.subplot(4,12,24+7+i+12*r, xticks=[], yticks=[])\n","#             plt.imshow(fmap_history_BN[ep][i+r*5], cmap=\"gray\")\n","#             plt.title(f\"layer {i+r*5}\")\n","    \n","#     plt.tight_layout(pad=0,h_pad=0,w_pad=0,rect=(0,0,0,0))\n","    \n","# ani = FuncAnimation(fig, animate, frames=range(0,100), interval=50) \n","# # frames 에 10 넣으면 for i in range(10) 이라고 보면 됨. 혹은 list 넣어주면 in list\n","# ani.save(save_video_path, writer='imagemagick')\n","# # %%\n","# fig = plt.figure(figsize=[25,10])\n","# def animate(ep):\n","#     plt.clf()\n","#     plt.suptitle(f\"Epoch: {range(1,EPOCH+1)[ep]}, # of conv block = {NoB}, # of channels = {NoC}\")\n","#     for r in range(2):\n","#         for i in range(5):\n","#             ax = plt.subplot(2,5,1+i+5*r, projection=\"3d\")\n","#             plot_hist(ax, befAct_history_No[ep], layer=i+5*r, hist_max=hist_mean_max_No[i+5*r])\n","#             plt.title(f\"layer {i+5*r}\")\n","\n","#     # plt.tight_layout()\n","    \n","# ani = FuncAnimation(fig, animate, frames=range(0,100), interval=50)\n","# ani.save(save_video_path2, writer='imagemagick')\n","# # %%\n","# fig = plt.figure(figsize=[25,10])\n","# def animate(ep):\n","#     plt.clf()\n","#     plt.suptitle(f\"Epoch: {range(1,EPOCH+1)[ep]}, # of conv block = {NoB}, # of channels = {NoC}\")\n","#     for r in range(2):\n","#         for i in range(5):\n","#             ax = plt.subplot(2,5,1+i+5*r, projection=\"3d\")\n","#             plot_hist(ax, befAct_history_BN[ep], layer=i+5*r, hist_max=hist_mean_max_BN[i+5*r])\n","#             plt.title(f\"layer {i+5*r}\")\n","    \n","#     # plt.tight_layout()\n","    \n","# ani = FuncAnimation(fig, animate, frames=range(0,100), interval=50)\n","# ani.save(save_video_path3, writer='imagemagick')"],"metadata":{"id":"DUBdy7StYVJN","executionInfo":{"status":"ok","timestamp":1674012768115,"user_tz":-540,"elapsed":7,"user":{"displayName":"강사","userId":"16181995035441534154"}}},"execution_count":20,"outputs":[]}]}