{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 데이터 로드"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "datasets = load_iris()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['data', 'target', 'frame', 'target_names', 'DESCR', 'feature_names', 'filename', 'data_module'])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datasets.keys() # dict타입!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[5.1, 3.5, 1.4, 0.2],\n",
       "       [4.9, 3. , 1.4, 0.2],\n",
       "       [4.7, 3.2, 1.3, 0.2],\n",
       "       [4.6, 3.1, 1.5, 0.2],\n",
       "       [5. , 3.6, 1.4, 0.2]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_data = datasets[\"data\"]\n",
    "x_data[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "target : [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2], names : ['setosa' 'versicolor' 'virginica']\n"
     ]
    }
   ],
   "source": [
    "y_data = datasets[\"target\"]\n",
    "print(f\"target : {y_data}, names : {datasets['target_names']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0],\n",
       "       [0],\n",
       "       [0]])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_data = y_data.reshape([-1,1]) # reshape\n",
    "y_data[:3]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### one-hot encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.]])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## 직접 원핫인코딩 적용\n",
    "onehot = np.zeros((len(y_data), len(datasets['target_names'])))\n",
    "\n",
    "for ind, y in enumerate(y_data):\n",
    "  onehot[ind][y] = 1\n",
    "\n",
    "onehot[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.]])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "enc = OneHotEncoder()\n",
    "enc.fit(y_data)  \n",
    "y_data = enc.transform(y_data).toarray()\n",
    "y_data[:10]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.22222222, 0.625     , 0.06779661, 0.04166667],\n",
       "       [0.16666667, 0.41666667, 0.06779661, 0.04166667],\n",
       "       [0.11111111, 0.5       , 0.05084746, 0.04166667]])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "min_max_scaler = MinMaxScaler()\n",
    "x_data_minmax = min_max_scaler.fit_transform(x_data)\n",
    "x_data_minmax[:3]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 데이터 매트릭스 및 가중치 함수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.        , 0.22222222, 0.625     , 0.06779661, 0.04166667],\n",
       "       [1.        , 0.16666667, 0.41666667, 0.06779661, 0.04166667],\n",
       "       [1.        , 0.11111111, 0.5       , 0.05084746, 0.04166667]])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_0 = np.ones(x_data_minmax.shape[0]) # x_data_minmax.shape[0] : 행 사이즈\n",
    "x_data_minmax = np.column_stack((x_0, x_data_minmax))\n",
    "\n",
    "x_data_minmax[:3] # 상수항 자리 만들어줌 (x0, x1, x2, x3, x4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.73647152, 0.55791304, 0.53174157, 0.36398027, 0.74676532],\n",
       "       [0.47094401, 0.66099187, 0.45226947, 0.41428082, 0.28292423],\n",
       "       [0.7413714 , 0.37890944, 0.64836039, 0.19878019, 0.83366674]])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weights = np.random.uniform(size=(3,5))\n",
    "weights # weigth function 생성 (w0, w1, w2, w3, w4)\n",
    "\n",
    "## 각 클래스마다 weight가 존재하기 때문에 3개의 행으로 만들어줌! -> 원래는 벡터 형식"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### softmax function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def softmax(z):\n",
    "    e = np.exp(z)\n",
    "    p = e / np.sum(np.exp(z), axis=1).reshape([-1,1])\n",
    "    return p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(150, 3)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "z = x_data_minmax.dot(weights.T) # weight와 x값의 linear comvination이므로!\n",
    "z.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.36157743, 0.26567361, 0.37274896],\n",
       "       [0.36245391, 0.26921754, 0.36832855],\n",
       "       [0.36070933, 0.26440791, 0.37488276],\n",
       "       [0.36124446, 0.26537094, 0.3733846 ],\n",
       "       [0.36083867, 0.26349875, 0.37566258]])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "softmax(z)[:5] # 각 클래스마다의 확률을 얻음"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Cost Function (Cross Entropy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cross_entropy_function(y, x, weights):\n",
    "    z = x_data_minmax.dot(weights.T)\n",
    "    result = - np.sum( # 각 케이스별 entropy를 모두 합산 한 것을 return\n",
    "                np.sum(\n",
    "                    (y * np.log(softmax(z))), axis=1).reshape((-1,1)) # y와 softmax(z)를 곱해주기 떄문에 결국엔 정답인 것만 남아 더해지게 된다\n",
    "                )\n",
    "    return result "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "171.2262714424512"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cross_entropy_function(y_data,x_data_minmax,weights)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Gradient descent (weights update)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def minimize_grdient(y, x, initial_weights, iterations = 500000, alpha=0.001):\n",
    "    cost_history= []\n",
    "    theta_history = []\n",
    "    m = y.shape[0]\n",
    "    theta = np.copy(initial_weights)\n",
    "    \n",
    "    number_of_classes = theta.shape[0]\n",
    "    number_of_weights = theta.shape[1]\n",
    "    \n",
    "    for _ in range(iterations):\n",
    "        original_theta = np.copy(theta) # weight값\n",
    "        \n",
    "        for k in range(number_of_classes):        \n",
    "            for j in range(number_of_weights):\n",
    "                partial_x = x[:, j] # 전체 데이터에서 가중치 j번째 값을 뽑아냄\n",
    "                partial_entropy = y - softmax(x.dot(original_theta.T))\n",
    "                # softmax(x.dot(original_theta.T)) : 각 클래스마다 내가 예측한 값 (y헷))\n",
    "                  # 실제 값에서 y값을 빼준 것!\n",
    "                theta[k][j]  = original_theta[k][j] + ( alpha * partial_entropy[:,k].dot(partial_x.T) ) /150 \n",
    "                # k번째 클래스 값만 뽑아서 partial_x.T와 곱해줌\n",
    "                  # (150,1)을 서로 dot 하여 하나의 값으로 나오게 됨! 하지만 값들을 모두 더해주기 떄문에 150으로 나누어줌\n",
    "        \n",
    "        if (_ % 10000) == 0:\n",
    "            print(cross_entropy_function(y,x,theta)/150)\n",
    "            cost_history.append(cross_entropy_function(y,x,theta))\n",
    "    \n",
    "    return theta, cost_history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.1413999998369357\n",
      "0.753791594146045\n",
      "0.612037164100472\n",
      "0.5362377701968719\n",
      "0.4874767590773951\n",
      "0.4524325946660678\n",
      "0.4254308326951758\n",
      "0.4036336809313542\n",
      "0.38544810766377025\n",
      "0.36990047912903606\n",
      "0.3563562834045034\n",
      "0.34438095409462066\n",
      "0.33366491200391946\n",
      "0.3239804655151998\n",
      "0.3151556705304917\n",
      "0.3070577615118938\n",
      "0.29958225461735216\n",
      "0.29264555410151616\n",
      "0.2861798000505995\n",
      "0.2801291942107574\n",
      "0.27444732653592413\n",
      "0.2690951950106894\n",
      "0.26403971559018347\n",
      "0.25925258492789205\n",
      "0.254709401167117\n",
      "0.2503889762673393\n",
      "0.24627279237301483\n",
      "0.2423445678182147\n",
      "0.23858990750395345\n",
      "0.23499601886933352\n",
      "0.23155147933895914\n",
      "0.2282460445219961\n",
      "0.22507048893648982\n",
      "0.2220164728917252\n",
      "0.21907643055877804\n",
      "0.2162434753193738\n",
      "0.21351131929425493\n",
      "0.21087420457786954\n",
      "0.2083268441925037\n",
      "0.20586437115567413\n",
      "0.20348229435470686\n",
      "0.20117646016046345\n",
      "0.19894301890221275\n",
      "0.19677839547815437\n",
      "0.19467926349925607\n",
      "0.19264252246398145\n",
      "0.190665277542968\n",
      "0.18874482161950878\n",
      "0.18687861928665256\n",
      "0.18506429254720907\n"
     ]
    }
   ],
   "source": [
    "# weights = minimize_grdient(y_data, x_data_minmax,weights)\n",
    "theta, cost_history = minimize_grdient(y_data, x_data_minmax, weights)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Confusion matrix for multiclass"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Class별로 True positive와 error로 분류\n",
    "- FN 행 기준, FP 열 기준으로 값 확인"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Precision for multiclass\n",
    "- TP/(TP+FP), 하나의 클래스와 나머지 col 클래스\n",
    "  - precision A = TP_A / (TP_A + FP_A) = TP_A / (TP_A + FP_AB + FP_AC + FP_AD)\n",
    "  *FP_AB : A인데 B로 잘못 예측한 것\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([123, 119,  66,  54, 114,  62, 113,  45,  15,  22,  67,  47,  64,\n",
       "       146, 144, 133,  36,  27,  75, 133, 118,  91,  80,  16,  22,   7,\n",
       "       134,  20, 112,  41])"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rand_index= np.random.randint(0,150,30)\n",
    "rand_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2, 1, 1, 1, 2, 1, 2, 0, 0, 0, 1, 0, 1, 2, 2, 1, 0, 0, 1, 1, 2, 1,\n",
       "       1, 0, 0, 0, 1, 0, 2, 0])"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = np.argmax(softmax(x_data_minmax[rand_index].dot(theta.T)),axis=1) # 각 클래스를 예측한 것 중 가장 확륯이 높은 것만 출력\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2, 2, 1, 1, 2, 1, 2, 0, 0, 0, 1, 0, 1, 2, 2, 2, 0, 0, 1, 2, 2, 1,\n",
       "       1, 0, 0, 0, 2, 0, 2, 0])"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_true = np.argmax(y_data[rand_index],axis=1) # 실제 정답\n",
    "y_true"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ True, False,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True, False,  True,  True,\n",
       "        True, False,  True,  True,  True,  True,  True,  True, False,\n",
       "        True,  True,  True])"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred == y_true"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8666666666666667"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(y_pred == y_true) / len(rand_index) # True인 경우에만 sum"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DL",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.15"
  },
  "vscode": {
   "interpreter": {
    "hash": "c6bda3511ced0b294abc79a4ddf63a34d3fd878babe321749fb3d1ff55e21abf"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
