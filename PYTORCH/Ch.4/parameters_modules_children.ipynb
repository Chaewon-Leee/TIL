{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch import optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 1])\n",
      "MLP(\n",
      "  (fc1): Sequential(\n",
      "    (0): Linear(in_features=2, out_features=3, bias=True)\n",
      "    (1): ReLU()\n",
      "  )\n",
      "  (fc2): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): ReLU()\n",
      "  )\n",
      "  (fc_out): Sequential(\n",
      "    (0): Linear(in_features=4, out_features=1, bias=True)\n",
      "    (1): Sigmoid()\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "class MLP(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.fc1 = nn.Sequential(nn.Linear(2,3),\n",
    "                                 nn.ReLU())\n",
    "        self.fc2 = nn.Sequential(nn.Linear(3,4),\n",
    "                                 nn.ReLU())\n",
    "        self.fc_out = nn.Sequential(nn.Linear(4,1),\n",
    "                                    nn.Sigmoid())\n",
    "    def forward(self,x):\n",
    "        x = self.fc1(x)\n",
    "        x = self.fc2(x)\n",
    "        x = self.fc_out(x)\n",
    "        return x\n",
    "\n",
    "model = MLP()\n",
    "print(model(torch.randn(2,2)).shape)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# .parameters() vs .modules() vs .children()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list(model.parameters())[0]\n",
    "# [layer0 weight 값, layer0 bias 값, layer1 weight 값, layer1 bias 값, ...]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fc1.0.weight\n",
      "Parameter containing:\n",
      "tensor([[-0.0592, -0.5752],\n",
      "        [ 0.5569,  0.2425],\n",
      "        [-0.2149,  0.6800]])\n",
      "fc1.0.bias\n",
      "Parameter containing:\n",
      "tensor([ 0.5418, -0.2572,  0.5098])\n",
      "fc2.0.weight\n",
      "Parameter containing:\n",
      "tensor([[ 0.2760,  0.0679, -0.0336],\n",
      "        [-0.3020,  0.5427,  0.2330],\n",
      "        [-0.5526,  0.3655,  0.1132],\n",
      "        [-0.1456, -0.3256,  0.0959]])\n",
      "fc2.0.bias\n",
      "Parameter containing:\n",
      "tensor([ 0.1120, -0.1363, -0.3668,  0.0619])\n",
      "fc_out.weight\n",
      "Parameter containing:\n",
      "tensor([[-0.1743, -0.2587,  0.2386,  0.0881],\n",
      "        [ 0.1163,  0.4118, -0.2429, -0.3380],\n",
      "        [-0.0698, -0.3627, -0.1248,  0.4156],\n",
      "        [-0.4624, -0.4776, -0.2725,  0.1400],\n",
      "        [ 0.3655, -0.1090,  0.4498, -0.2792],\n",
      "        [ 0.0872,  0.2323, -0.3417,  0.2330],\n",
      "        [ 0.0080, -0.2560,  0.2411,  0.3640],\n",
      "        [-0.3587,  0.2671, -0.2828,  0.0193],\n",
      "        [ 0.4867,  0.0601,  0.4136,  0.1392],\n",
      "        [ 0.0487, -0.1529,  0.4190,  0.2929]], requires_grad=True)\n",
      "fc_out.bias\n",
      "Parameter containing:\n",
      "tensor([ 0.3205,  0.2924, -0.2135,  0.1196,  0.3307,  0.0110, -0.0201,  0.4570,\n",
      "         0.2061, -0.3330], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "for name, p in model.named_parameters(): # named_parameters : 이름과 파라미터 함께 전달함\n",
    "    print(name)\n",
    "    print(p)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "transfer-learning 할 때 좋다 !\n",
    "- 만약 10개 분류하는 걸 들고와서, 5개 분류하는 모델로 재학습할 때, 기존에 학습했던 parameters를 사용할 수 있도록\n",
    "- 여기서 모델 weight를 들고 온다고 할 때, weight inital로 사용해도 되고, freeze해도 된다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n",
      "------------------------------\n",
      "[Parameter containing:\n",
      "tensor([[-0.1743, -0.2587,  0.2386,  0.0881],\n",
      "        [ 0.1163,  0.4118, -0.2429, -0.3380],\n",
      "        [-0.0698, -0.3627, -0.1248,  0.4156],\n",
      "        [-0.4624, -0.4776, -0.2725,  0.1400],\n",
      "        [ 0.3655, -0.1090,  0.4498, -0.2792],\n",
      "        [ 0.0872,  0.2323, -0.3417,  0.2330],\n",
      "        [ 0.0080, -0.2560,  0.2411,  0.3640],\n",
      "        [-0.3587,  0.2671, -0.2828,  0.0193],\n",
      "        [ 0.4867,  0.0601,  0.4136,  0.1392],\n",
      "        [ 0.0487, -0.1529,  0.4190,  0.2929]], requires_grad=True), Parameter containing:\n",
      "tensor([ 0.3205,  0.2924, -0.2135,  0.1196,  0.3307,  0.0110, -0.0201,  0.4570,\n",
      "         0.2061, -0.3330], requires_grad=True)]\n"
     ]
    }
   ],
   "source": [
    "# for tranfer learning\n",
    "model=MLP()\n",
    "\n",
    "for p in model.parameters(): # 전체 freeze\n",
    "    p.requires_grad=False # 미분 불가능하도록 False\n",
    "\n",
    "print([p for p in model.parameters() if p.requires_grad])\n",
    "print(\"-\"*30)\n",
    "model.fc_out = nn.Linear(4,10)\n",
    "\n",
    "params = [p for p in model.parameters() if p.requires_grad]\n",
    "print([p for p in model.parameters() if p.requires_grad])\n",
    "\n",
    "optimizer = optim.Adam(params, lr=0.1) # freeze된 param 빼고 전달"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<generator object Module.modules at 0x7f89608357b0>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.modules()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[MLP(\n",
       "   (fc1): Sequential(\n",
       "     (0): Linear(in_features=2, out_features=3, bias=True)\n",
       "     (1): ReLU()\n",
       "   )\n",
       "   (fc2): Sequential(\n",
       "     (0): Linear(in_features=3, out_features=4, bias=True)\n",
       "     (1): ReLU()\n",
       "   )\n",
       "   (fc_out): Linear(in_features=4, out_features=10, bias=True)\n",
       " ),\n",
       " Sequential(\n",
       "   (0): Linear(in_features=2, out_features=3, bias=True)\n",
       "   (1): ReLU()\n",
       " ),\n",
       " Linear(in_features=2, out_features=3, bias=True),\n",
       " ReLU(),\n",
       " Sequential(\n",
       "   (0): Linear(in_features=3, out_features=4, bias=True)\n",
       "   (1): ReLU()\n",
       " ),\n",
       " Linear(in_features=3, out_features=4, bias=True),\n",
       " ReLU(),\n",
       " Linear(in_features=4, out_features=10, bias=True)]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(model.modules())\n",
    "# MLP 안에 있는 fc1, fc2, fc_out 먼저 확인\n",
    "  # fc1 속에 있는 Sequential 확인 > 내용물 확인\n",
    "  # fc2 속에 있는 Sequential 확인 > 내용물 확인\n",
    "  # fc_out 속에 있는 Sequential 확인 > 내용물 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Linear(in_features=2, out_features=3, bias=True), Linear(in_features=3, out_features=4, bias=True), Linear(in_features=4, out_features=10, bias=True)]\n"
     ]
    }
   ],
   "source": [
    "print([m for m in model.modules() if isinstance(m,nn.Linear)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Parameter containing:\n",
      "tensor([[1., 1.],\n",
      "        [1., 1.],\n",
      "        [1., 1.]]), Parameter containing:\n",
      "tensor([[1., 1., 1.],\n",
      "        [1., 1., 1.],\n",
      "        [1., 1., 1.],\n",
      "        [1., 1., 1.]]), Parameter containing:\n",
      "tensor([[1., 1., 1., 1.],\n",
      "        [1., 1., 1., 1.],\n",
      "        [1., 1., 1., 1.],\n",
      "        [1., 1., 1., 1.],\n",
      "        [1., 1., 1., 1.],\n",
      "        [1., 1., 1., 1.],\n",
      "        [1., 1., 1., 1.],\n",
      "        [1., 1., 1., 1.],\n",
      "        [1., 1., 1., 1.],\n",
      "        [1., 1., 1., 1.]], requires_grad=True)]\n"
     ]
    }
   ],
   "source": [
    "# weight initialization에 활용\n",
    "for m in model.modules():\n",
    "    if isinstance(m, nn.Linear):\n",
    "        # nn.init.kaiming_normal_(m.weight) # nn.Linear에 해당하는 weight init\n",
    "        nn.init.constant_(m.weight, 1) # 아예 1로 바꿔버리는 것\n",
    "\n",
    "print([m.weight for m in model.modules() if isinstance(m, nn.Linear)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n"
     ]
    }
   ],
   "source": [
    "print([m.weight for m in [model.parameters()] if isinstance(m, nn.Linear)]) # parameters 안됨"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### children"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<generator object Module.children at 0x7f8960835e40>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.children()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Sequential(\n",
       "   (0): Linear(in_features=2, out_features=3, bias=True)\n",
       "   (1): ReLU()\n",
       " ),\n",
       " Sequential(\n",
       "   (0): Linear(in_features=3, out_features=4, bias=True)\n",
       "   (1): ReLU()\n",
       " ),\n",
       " Linear(in_features=4, out_features=10, bias=True)]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(model.children()) # fc1, fc2, fc_out만 해서 내용물만 보여준다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1.7479, 0.9489, 1.7159],\n",
       "        [0.0000, 0.0000, 0.0000]])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.randn(2,2)\n",
    "list(model.children())[0](x) # 각 레이어에 접근 가능"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sequential(\n",
      "  (0): Sequential(\n",
      "    (0): Linear(in_features=2, out_features=3, bias=True)\n",
      "    (1): ReLU()\n",
      "  )\n",
      "  (1): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): ReLU()\n",
      "  )\n",
      ")\n",
      "tensor([[4.5248, 4.2764, 4.0459, 4.4747],\n",
      "        [0.1120, 0.0000, 0.0000, 0.0619]])\n"
     ]
    }
   ],
   "source": [
    "sub_network = nn.Sequential(*list(model.children())[:2]) # 서브 네트워크를 만들어줄 수 있다\n",
    "print(sub_network)\n",
    "print(sub_network(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DL",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
