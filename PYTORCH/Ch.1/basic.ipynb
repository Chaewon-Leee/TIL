{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pytorch Basic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tensor Basic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1, 2, 3, 4])\n",
      "[1 2 3 4]\n",
      "\n",
      "\n",
      "type : <class 'torch.Tensor'>\n",
      "data type : torch.int64\n",
      "shape : torch.Size([4])\n"
     ]
    }
   ],
   "source": [
    "a = torch.tensor([1,2,3,4])\n",
    "a_np = np.array([1,2,3,4])\n",
    "\n",
    "print(a)\n",
    "print(a_np)\n",
    "print(\"\\n\")\n",
    "\n",
    "print(f\"type : {type(a)}\")\n",
    "print(f\"data type : {a.dtype}\")\n",
    "print(f\"shape : {a.shape}\") # == a.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.float32\n",
      "tensor([1.0000, 2.0000, 3.1000, 4.0000])\n"
     ]
    }
   ],
   "source": [
    "b = torch.tensor([1,2,3.1    ,4])\n",
    "print(b.dtype) # 실수가 하나라도 들어갈 경우, 자동으로 실수 타입으로 변환\n",
    "print(b) # 다른 int 또한 실수 타입으로 변환"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1, 2],\n",
      "        [3, 4]])\n",
      "\n",
      "\n",
      "shape : torch.Size([2, 2])\n",
      "차원 수 : 2\n",
      "전체 성분 수 : 4\n"
     ]
    }
   ],
   "source": [
    "A = torch.tensor([[1,2], [3,4]])\n",
    "print(A)\n",
    "### 행렬이기 때문에 각 행에 해당하는 숫자의 개수 일치 필요\n",
    "# A = torch.tensor([[1,2], [3,4, 5, 6]])\n",
    "print(\"\\n\")\n",
    "\n",
    "print(f\"shape : {A.shape}\") # 2x2\n",
    "print(f\"차원 수 : {A.ndim}\") # 2차원\n",
    "print(f\"전체 성분 수 : {A.numel()}\") # = np.size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[ 1,  2,  3],\n",
      "         [ 4,  5,  6],\n",
      "         [ 7,  8,  9]],\n",
      "\n",
      "        [[10, 11, 12],\n",
      "         [14, 15, 16],\n",
      "         [17, 18, 19]]])\n",
      "A shape : torch.Size([2, 3, 3])\n",
      "a shape : torch.Size([1, 1, 4])\n"
     ]
    }
   ],
   "source": [
    "A = torch.tensor([ [[1,2,3],[4,5,6],[7,8,9]],\n",
    "                  [[10,11,12],[14,15,16],[17,18,19]]])\n",
    "print(A)\n",
    "print(f\"A shape : {A.shape}\")\n",
    "\n",
    "a = torch.tensor([[[1,2,3,4]]])\n",
    "print(f\"a shape : {a.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- shape 표기법 : 채널 개수, 행, 열\n",
    "- [] (차원) 가 하나씩 추가될 때마다, 이에 대한 개수가 왼쪽부터 추가가 된다\n",
    "\n",
    "- 만약 4차원일 경우, >> 개수, 개수, 행, 열"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1, 2, 3],\n",
      "        [4, 5, 6],\n",
      "        [7, 8, 9]])\n",
      "A shape : torch.Size([3, 3])\n",
      "tensor([[[1, 2, 3],\n",
      "         [4, 5, 6],\n",
      "         [7, 8, 9]]])\n",
      "a shape : torch.Size([1, 3, 3])\n"
     ]
    }
   ],
   "source": [
    "A = torch.tensor([[1,2,3],[4,5,6],[7,8,9]])\n",
    "print(A)\n",
    "print(f\"A shape : {A.shape}\")\n",
    "\n",
    "A = torch.tensor([[[1,2,3],[4,5,6],[7,8,9]]])\n",
    "print(A)\n",
    "print(f\"a shape : {A.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0., 0., 0., 0., 0.])\n",
      "tensor([[[0, 0, 0],\n",
      "         [0, 0, 0],\n",
      "         [0, 0, 0]],\n",
      "\n",
      "        [[0, 0, 0],\n",
      "         [0, 0, 0],\n",
      "         [0, 0, 0]]])\n",
      "tensor([[0., 0., 0.],\n",
      "        [0., 0., 0.],\n",
      "        [0., 0., 0.]])\n",
      "\n",
      "\n",
      "tensor([1., 1., 1., 1., 1.])\n",
      "\n",
      "\n",
      "tensor([3, 5, 7, 9])\n",
      "tensor([0.0000, 0.1000, 0.2000, 0.3000, 0.4000, 0.5000, 0.6000, 0.7000, 0.8000,\n",
      "        0.9000])\n",
      "\n",
      "\n",
      "tensor([0.0000, 0.1111, 0.2222, 0.3333, 0.4444, 0.5556, 0.6667, 0.7778, 0.8889,\n",
      "        1.0000])\n",
      "tensor([0.0000, 0.2222, 0.4444, 0.6667, 0.8889, 1.1111, 1.3333, 1.5556, 1.7778,\n",
      "        2.0000])\n"
     ]
    }
   ],
   "source": [
    "print(torch.zeros(5)) # 5개의 zeors tensor\n",
    "print(torch.zeros_like(A)) # A와 동일한 shape의 zeros\n",
    "print(torch.zeros(3,3)) # 3x3 tensor zero로 생성\n",
    "# print(torch.zeros( (3,3)) ) # 튜플을 입력으로 넣어도 된다\n",
    "print(\"\\n\")\n",
    "\n",
    "print(torch.ones(5)) # 5개의 ones tensor\n",
    "print(\"\\n\")\n",
    "\n",
    "print(torch.arange(3,10,2)) # range랑 동일하게 tensor 만듦\n",
    "print(torch.arange(0,1,0.1)) # 소수점도 가능\n",
    "print(\"\\n\")\n",
    "\n",
    "print(torch.linspace(0,1,10)) # 시작점 : 0, 끝 점 : 1, 개수 : 10개로 간격 맞춰 생성\n",
    "print(torch.linspace(0,2,10)) # 시작점 : 0, 끝 점 : 2, 개수 : 10개로 간격 맞춰 생성"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "arange vs linxpace\n",
    "\n",
    "- arange : (x,y,z) 중 z 간격을 기준으로 생성\n",
    "- linxpace : (x,y,z) 중 z개를 생성"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tensor간의 연산"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 6,  8, 10, 12])\n",
      "\n",
      "\n",
      "tensor([[4, 6],\n",
      "        [4, 6]])\n",
      "tensor([[-2, -2],\n",
      "        [-2, -2]])\n"
     ]
    }
   ],
   "source": [
    "a = torch.tensor([1,2,3,4])\n",
    "b = torch.tensor([5,6,7,8])\n",
    "print(a+b)\n",
    "print(\"\\n\")\n",
    "\n",
    "A = torch.tensor([[1,2], [1,2]])\n",
    "B = torch.tensor([[3,4], [3,4]])\n",
    "print(A+B)\n",
    "print(A-B)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[3, 8],\n",
      "        [3, 8]])\n",
      "tensor([[0.3333, 0.5000],\n",
      "        [0.3333, 0.5000]])\n",
      "tensor([[ 9, 16],\n",
      "        [ 9, 16]])\n"
     ]
    }
   ],
   "source": [
    "print(A*B) # Hadamard Product = element-wise 곱셈\n",
    "print(A/B)\n",
    "print(B**2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "곱셈, 나눗셈, 제곱 > 각 성분에 대해서 해준다\n",
    "\n",
    "- Hadamard 계산이기 때문에 동일한 shape를 가진 tensor에 적용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 9, 12],\n",
      "        [ 9, 12]])\n"
     ]
    }
   ],
   "source": [
    "print(A@B) # 내적 = dot product"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "|                              Hadamard Product                               | 내적 |\n",
    "| :----------------------------------------------------------------: | :----------: |\n",
    "|각 원소별로 곱셈값|일반적인 행렬 곱셈|\n",
    "|= element-wise 곱셈|= dot product|"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "행렬곱셈\n",
    "\n",
    "- (x,y)@(a,b) > y = a가 맞아야 성립"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tensor 인덱싱"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Boolean으로 인덱싱"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n",
      "\n",
      "\n",
      "tensor([[False, False,  True, False],\n",
      "        [False,  True, False,  True]])\n",
      "tensor([3, 3, 3])\n"
     ]
    }
   ],
   "source": [
    "a = [1,2,3,5,4,6,3,3]\n",
    "print(a==3) # 리스트 =/= 3이므로, False\n",
    "print(\"\\n\")\n",
    "\n",
    "A = torch.tensor([[1,2,3,4],[5,3,7,3]])\n",
    "print(A==3) # 각 성분에 대해 해당 값과 동일한지 비교해주게 된다\n",
    "print(A[A==3]) # 성분가 3과 동일한 값들로 인덱싱"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1, 2],\n",
      "        [7, 8]])\n",
      "tensor([1, 3, 4])\n",
      "torch.Size([4])\n"
     ]
    }
   ],
   "source": [
    "A=torch.tensor([[1,2],[3,4],[5,6],[7,8]])\n",
    "B=torch.tensor([True,False,False,True]) # 그냥 리스트여도 가능하다! tensor type 맞춰줄 필요 없다\n",
    "print(A[B,:])\n",
    "# 행 자리에 boolean tensor를 넣어주어 해당 boolean에 따라서 True인 행에 대해서 출력\n",
    "\n",
    "b=torch.tensor([1,2,3,4]) # 4\n",
    "print(b[[True,False,True,True]])\n",
    "print(b.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "list indices must be integers or slices, not list",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/Users/lee/Desktop/workspace/git/TIL/Pytorch/Ch.1/basic.ipynb 셀 23\u001b[0m line \u001b[0;36m2\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/lee/Desktop/workspace/git/TIL/Pytorch/Ch.1/basic.ipynb#X30sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m c\u001b[39m=\u001b[39m[\u001b[39m1\u001b[39m,\u001b[39m2\u001b[39m,\u001b[39m3\u001b[39m,\u001b[39m4\u001b[39m]\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/lee/Desktop/workspace/git/TIL/Pytorch/Ch.1/basic.ipynb#X30sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m c[[\u001b[39mTrue\u001b[39;49;00m,\u001b[39mFalse\u001b[39;49;00m,\u001b[39mFalse\u001b[39;49;00m,\u001b[39mTrue\u001b[39;49;00m]]\n",
      "\u001b[0;31mTypeError\u001b[0m: list indices must be integers or slices, not list"
     ]
    }
   ],
   "source": [
    "c=[1,2,3,4]\n",
    "c[[True,False,False,True]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- tensor은 가능하지만, list는 불가능하다"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tensor로 인덱싱"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(3)\n",
      "tensor(3)\n",
      "\n",
      "tensor([3, 4, 5])\n",
      "tensor([[3, 3, 3],\n",
      "        [4, 4, 4]])\n"
     ]
    }
   ],
   "source": [
    "a=torch.tensor([1,2,3,4,5])\n",
    "print(a[2])\n",
    "print( a[torch.tensor(2)] ) # tensor로도 접근 가능\n",
    "print()\n",
    "print( a[torch.tensor([2,3,4])] )\n",
    "print( a[torch.tensor([[2,2,2],[3,3,3]])] )\n",
    "# 각 인덱싱에 부합하는 값으로, tensor shape에 맞춰 tensor 반환!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1, 2, 3],\n",
      "        [4, 5, 6]])\n",
      "tensor([[[1, 2, 3],\n",
      "         [4, 5, 6]],\n",
      "\n",
      "        [[4, 5, 6],\n",
      "         [4, 5, 6]]])\n",
      "torch.Size([2, 2, 3])\n"
     ]
    }
   ],
   "source": [
    "a=torch.tensor([[1,2,3],[4,5,6]])\n",
    "print(a)\n",
    "\n",
    "print( a[torch.tensor([[0,1],[1,1]])] )\n",
    "# a[0] = [1,2,3] 이므로, 앞과 마찬가지로 인덱싱 값에 따라 각 위치에 맞게 tensor 반환\n",
    "print( a[torch.tensor([[0,1],[1,1]])].shape )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "segmentation 결과 그림 보여줄 때, tensor 인덱싱을 활용!\n",
    "- 만약 고양이 그림 (5)을 주황색으로 칠한다고 하자\n",
    "- 해당 5번째 인덱스를 가진 그림에 대해 3개의 값인 RGB값을 부여해야 하므로, 이때 활용한다"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 인덱싱 종류 정리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(2.)\n",
      "\n",
      "tensor([2., 5., 6., 8.])\n",
      "tensor([2.])\n",
      "\n",
      "tensor([2.])\n",
      "\n",
      "tensor([[3., 4.],\n",
      "        [5., 6.],\n",
      "        [5., 6.],\n",
      "        [3., 4.],\n",
      "        [5., 6.]])\n"
     ]
    }
   ],
   "source": [
    "A = torch.Tensor([[1,2],[3,4],[5,6],[7,8]])\n",
    "\n",
    "# 1.\n",
    "print(A[0,1])\n",
    "print()\n",
    "# 2.\n",
    "print(A[ torch.tensor([[False,True],[False,False],[True,True],[False,True]]) ])\n",
    "print(A[A==2])\n",
    "print()\n",
    "# 3.\n",
    "print(A[ [True,False,False,False],[False,True] ])\n",
    "print()\n",
    "# 4.\n",
    "print(A[ torch.tensor([1,2,2,1,2]) ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 3])\n",
      "tensor([2., 9., 5., 6., 9., 9.])\n",
      "tensor([2., 9.])\n"
     ]
    }
   ],
   "source": [
    "A = torch.Tensor([[1,2,9],[5,6,9],[7,8,9]])\n",
    "print(A.shape)\n",
    "\n",
    "# 2.\n",
    "print(A[ torch.tensor([[False,True,True],[True,True,True],[False,False,True]]) ])\n",
    "# 3.\n",
    "print(A[ [True,False,False],[False,True,True] ])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2번\n",
    "- 2와 같은 경우에는, A와 shape를 맞춰주어 동일한 인덱스를 가진 값이 True일 때만 출력하는 것\n",
    "<img src=\"image/boolean_indexing3.jpeg\" width=\"300\">\n",
    "\n",
    "3번\n",
    "- 3과 같은 경우, A shape 수와 일치하는 행렬을 통해 각 행과 열이 True인지 부여하는 것\n",
    "<img src=\"image/boolean_indexing1.jpeg\" width=\"300\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pytorch의 여러 함수들"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.9811, 0.9538, 0.6762],\n",
      "        [0.9342, 0.8575, 0.1080],\n",
      "        [0.2240, 0.7824, 0.7007]])\n",
      "\n",
      "tensor([[-0.9383,  0.7463, -0.3835],\n",
      "        [ 1.7961,  0.7976,  0.4311],\n",
      "        [ 0.5847,  0.7438, -0.1169]])\n"
     ]
    }
   ],
   "source": [
    "A=torch.rand(3,3) # 0과 1 사이의 uniform 분포에서 랜덤 샘플링\n",
    "print(A)\n",
    "print()\n",
    "B=torch.randn(3,3) # 평균 : 0, 분산 : 1인 정규분포에서 랜덤 샘플링\n",
    "print(B)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.6403, -0.4638,  0.7515],\n",
      "        [-2.6443,  1.1417, -0.5035],\n",
      "        [-0.8537,  0.0849,  0.1644]])\n",
      "\n",
      "tensor([[0.6403, 0.4638, 0.7515],\n",
      "        [2.6443, 1.1417, 0.5035],\n",
      "        [0.8537, 0.0849, 0.1644]])\n",
      "tensor([[0.8002, 0.6810, 0.8669],\n",
      "        [1.6261, 1.0685, 0.7096],\n",
      "        [0.9240, 0.2914, 0.4054]])\n",
      "tensor([[1.8970, 0.6289, 2.1201],\n",
      "        [0.0711, 3.1321, 0.6044],\n",
      "        [0.4258, 1.0886, 1.1787]])\n",
      "\n",
      "tensor([[-0.4459, -0.7683, -0.2858],\n",
      "        [ 0.9724,  0.1325, -0.6861],\n",
      "        [-0.1581, -2.4661, -1.8055]])\n",
      "tensor(1.)\n",
      "tensor(1.)\n"
     ]
    }
   ],
   "source": [
    "A=torch.randn(3,3)\n",
    "print(A)\n",
    "print()\n",
    "\n",
    "print(torch.abs(A)) # 절대값\n",
    "print(torch.sqrt(torch.abs(A))) # square root\n",
    "print(torch.exp(A)) # e^A\n",
    "# 각 값에 대해 e^a11 e^a21 e^a31 ... 한 행렬 값이 나온다\n",
    "# torch.exp(1) > 이와 같이 int를 넣으면, 에러! tensor로 넣어줘야 한다\n",
    "  # => torch.exp(torch.tensor(1))\n",
    "print()\n",
    "\n",
    "print(torch.log(torch.abs(A))) # 밑이 e인 log\n",
    "print(torch.log10(torch.tensor(10))) # 밑이 10인 log\n",
    "print(torch.log2(torch.tensor(2))) # 밑이 2인 log\n",
    "# 함수로 정의된 것이다! log3 처럼 밑 변경하는 것 아님"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 1., -0.,  1.],\n",
      "        [-3.,  1., -1.],\n",
      "        [-1.,  0.,  0.]])\n",
      "tensor([[ 0.6400, -0.4600,  0.7500],\n",
      "        [-2.6400,  1.1400, -0.5000],\n",
      "        [-0.8500,  0.0800,  0.1600]])\n",
      "\n",
      "tensor([[ 0., -1.,  0.],\n",
      "        [-3.,  1., -1.],\n",
      "        [-1.,  0.,  0.]])\n",
      "tensor([[ 1., -0.,  1.],\n",
      "        [-2.,  2., -0.],\n",
      "        [-0.,  1.,  1.]])\n"
     ]
    }
   ],
   "source": [
    "print(torch.round(A))\n",
    "print(torch.round(A, decimals=2))\n",
    "# np에서는 그냥 적어도 상관 없었지만, torch에서는 decimals를 적어줘야 한다\n",
    "print()\n",
    "\n",
    "print(torch.floor(A)) # 내림\n",
    "print(torch.ceil(A)) # 올림"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.5000)\n",
      "tensor(0.5000)\n",
      "tensor(1.)\n",
      "tensor(-1.)\n"
     ]
    }
   ],
   "source": [
    "print(torch.sin(torch.tensor(torch.pi/6)))\n",
    "# type(torch.pi)자체는 float이기 때문에 tensor로 변환해서 sin 함수 안에 넣어줘야 한다\n",
    "# torch.Tensor(3.14/6)의 type은 tensor로 나오므로, tensor로 변환 안해줘도 됨!\n",
    "print(torch.cos(torch.tensor(torch.pi/3)))\n",
    "print(torch.tan(torch.tensor(torch.pi/4)))\n",
    "print(torch.tanh(torch.tensor(-10)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(nan)\n",
      "\n",
      "tensor([False, False,  True, False, False])\n",
      "tensor([False, False,  True, False, False])\n"
     ]
    }
   ],
   "source": [
    "torch.nan # not a number\n",
    "print(torch.log(torch.tensor(-1))) # 숫자가 아니기 때문에 nan으로 출력\n",
    "print()\n",
    "print(torch.isnan(torch.tensor([1,2,torch.nan,3,4])))\n",
    "# 각 성분에 대해 nan인지 boolean으로 출력하는 것\n",
    "\n",
    "torch.inf # 무한대\n",
    "print(torch.isinf(torch.tensor([1,2,torch.inf,3,4])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.3372,  3.8510, -0.0975,  1.6552],\n",
      "        [-0.8190,  1.5040,  0.1118,  0.5201],\n",
      "        [-2.1515, -0.1471, -0.0946, -1.2219]])\n",
      "\n",
      "tensor(3.8510)\n",
      "torch.return_types.max(\n",
      "values=tensor([ 3.8510,  1.5040, -0.0946]),\n",
      "indices=tensor([1, 1, 2]))\n",
      "torch.return_types.max(\n",
      "values=tensor([[ 3.8510],\n",
      "        [ 1.5040],\n",
      "        [-0.0946]]),\n",
      "indices=tensor([[1],\n",
      "        [1],\n",
      "        [2]]))\n"
     ]
    }
   ],
   "source": [
    "A=torch.randn(3,4)\n",
    "print(A)\n",
    "print()\n",
    "print(torch.max(A))\n",
    "print(torch.max(A,dim=1)) # axis도 동작하긴 한다\n",
    "  # dim=1 행, dim=0 열\n",
    "# 1번째 dimension이니까, 3개의 행 값 중에서 가장 큰 것 출력\n",
    "# dim을 사용하면, 각 행/열 중 가장 큰 값에 대한 인덱스도 함게 출력\n",
    "print(torch.max(A,dim=1, keepdims=True))\n",
    "# keepdims: input과 동일한 shape로 출력\n",
    "  # max의 경우, (3)으로 변하지만 keepdims은 (3,1)으로 맞춰서 나온다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(-2.6443)\n",
      "torch.return_types.min(\n",
      "values=tensor([-2.6443, -0.4638, -0.5035]),\n",
      "indices=tensor([1, 0, 1]))\n",
      "\n",
      "tensor([[ 0.6403, -0.4638,  0.7515],\n",
      "        [-2.6443,  1.1417, -0.5035],\n",
      "        [-0.8537,  0.0849,  0.1644]])\n",
      "tensor(4)\n",
      "tensor([0, 1, 0])\n"
     ]
    }
   ],
   "source": [
    "print(torch.min(A))\n",
    "print(torch.min(A,dim=0))\n",
    "print()\n",
    "print(A)\n",
    "print(torch.argmax(A))\n",
    "print(torch.argmax(A,dim=0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "max vs argmax\n",
    "- max : 함수 값 (y) 중 제일 큰 값\n",
    "- argmax : 제일 큰 값인 y를 가질 때의 x 값\n",
    "\n",
    "=> 즉, max 함수와 dim이 동일할 경우, 나오는 index값이 동일하다\n",
    "- 다만 max는 값과 인덱스, 함께 나오며 argmax는 인덱스만 출력해주는 것"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "sum, mean, std도 있다!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 1.3419],\n",
      "        [-1.4605],\n",
      "        [ 0.3285],\n",
      "        [-0.0048],\n",
      "        [-0.4916],\n",
      "        [-0.9996]])\n",
      "torch.return_types.sort(\n",
      "values=tensor([[-1.4605],\n",
      "        [-0.9996],\n",
      "        [-0.4916],\n",
      "        [-0.0048],\n",
      "        [ 0.3285],\n",
      "        [ 1.3419]]),\n",
      "indices=tensor([[1],\n",
      "        [5],\n",
      "        [4],\n",
      "        [3],\n",
      "        [2],\n",
      "        [0]]))\n"
     ]
    }
   ],
   "source": [
    "a=torch.randn(6,1)\n",
    "print(a)\n",
    "print(torch.sort(a,dim=0))\n",
    "# 기본적으로 dim=1에 대해 sort하기 때문에, 꼭 dim를 남겨야 한다 !\n",
    "# 오름차순 기본 만약 내림차순을 원한다면 descending=True 추가\n",
    "# = a.sort() 또한 가능"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "sort와 같이 max, abs 또한 tensor에 직접 접근하는 것이 아닌 클래스내의 메소드로 접근 가능!\n",
    "- max(), abs()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.3432,  0.0192],\n",
      "        [-1.1015,  0.1584],\n",
      "        [ 0.6346,  3.5619],\n",
      "        [ 0.3559, -0.0965],\n",
      "        [ 1.5236,  0.1649],\n",
      "        [-2.1803, -0.1062]])\n",
      "tensor([[ 0.3432, -1.1015,  0.6346,  0.3559,  1.5236, -2.1803],\n",
      "        [ 0.0192,  0.1584,  3.5619, -0.0965,  0.1649, -0.1062]])\n",
      "torch.Size([2, 6])\n",
      "\n",
      "tensor([[ 0.3432, -1.1015,  0.6346,  0.3559,  1.5236, -2.1803],\n",
      "        [ 0.0192,  0.1584,  3.5619, -0.0965,  0.1649, -0.1062]])\n",
      "tensor([[ 0.3432, -1.1015,  0.6346,  0.3559,  1.5236, -2.1803],\n",
      "        [ 0.0192,  0.1584,  3.5619, -0.0965,  0.1649, -0.1062]])\n",
      "\n"
     ]
    }
   ],
   "source": [
    "a=torch.randn(6,2)\n",
    "\n",
    "print(a)\n",
    "print(a.transpose(1,0))\n",
    "print(a.transpose(1,0).shape)\n",
    "print()\n",
    "print(a.permute(1,0)) # 3차원 이상부터!\n",
    "print(a.T) # 정 transpose\n",
    "# = a.t()@b\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[ 0.9359, -0.3400,  0.1906],\n",
      "         [-1.3374, -1.2386,  0.3413],\n",
      "         [-0.3114,  0.8615, -0.7548],\n",
      "         [-0.6752, -1.7877, -2.3720],\n",
      "         [ 0.7999,  1.1923,  0.6779],\n",
      "         [ 1.9540,  0.2970,  1.3421]],\n",
      "\n",
      "        [[ 0.1849,  1.3251,  0.5701],\n",
      "         [-1.2081,  0.7018,  1.0157],\n",
      "         [-0.8808, -1.0474,  1.8949],\n",
      "         [ 0.0247,  1.4308,  1.0180],\n",
      "         [ 2.0461, -0.8170,  1.3961],\n",
      "         [-0.5640,  0.4605,  0.0742]],\n",
      "\n",
      "        [[-0.1733, -0.1363,  0.1631],\n",
      "         [-0.9583, -0.3553,  0.7722],\n",
      "         [ 2.3356, -0.6815, -2.2323],\n",
      "         [-0.7312,  1.8947, -0.4968],\n",
      "         [-0.5564,  0.8773,  0.4471],\n",
      "         [-1.9082,  0.0905,  0.6545]],\n",
      "\n",
      "        [[-0.3368,  1.0990,  0.1841],\n",
      "         [-0.7049, -0.8579,  0.1795],\n",
      "         [ 0.8643,  1.1305,  0.0949],\n",
      "         [ 0.7231,  0.3684, -1.2087],\n",
      "         [ 0.3952,  1.2895, -0.5697],\n",
      "         [ 0.7637,  1.6949, -1.1531]]])\n",
      "torch.Size([4, 6, 3])\n",
      "torch.Size([4, 6, 3])\n"
     ]
    }
   ],
   "source": [
    "A=torch.randn(4,3,6)\n",
    "print(A.permute(0,2,1))\n",
    "print(A.permute(0,2,1).shape)\n",
    "# 0번째에 0번째, 1번째에 2번째, 3번째엔 1번째\n",
    "print(A.transpose(2,1).shape) # transpose는 두개만 자리 바꿀 수 있음"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([3, 2, 4, 3, 4, 3, 3, 3, 2, 3, 2, 3])\n",
      "torch.Size([12])\n",
      "tensor([[[3, 2, 4],\n",
      "         [3, 4, 3]],\n",
      "\n",
      "        [[3, 3, 2],\n",
      "         [3, 2, 3]]])\n",
      "3\n"
     ]
    }
   ],
   "source": [
    "A=torch.randint(1,5,size=(12,))\n",
    "# 1부터 5미만 12개 정수 랜덤하게 추출\n",
    "  # 1 차원은 (N,)\n",
    "print(A)\n",
    "print(A.shape)\n",
    "\n",
    "B=A.reshape(2,2,3) # 2행 3열짜리 2개로 shape을 바꿔달라!\n",
    "  # 12개면 3으로 먼저 끊고 > 3개짜리를 2개로 묶고 > 이를 2개로 만든다\n",
    "  # 이처럼 뒤에서부터 수행하기 때문에 동일한 shape를 가졌더라도 다른 값이 들어갈 수 있으니 유의!\n",
    "print(B)\n",
    "print(B.ndim) # 3차원 행렬"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n",
      "        18, 19])\n",
      "tensor([[ 0,  1,  2,  3,  4],\n",
      "        [ 5,  6,  7,  8,  9],\n",
      "        [10, 11, 12, 13, 14],\n",
      "        [15, 16, 17, 18, 19]])\n",
      "torch.Size([4, 5])\n",
      "\n",
      "torch.Size([1, 20])\n",
      "torch.Size([20, 1])\n"
     ]
    }
   ],
   "source": [
    "A=torch.arange(20)\n",
    "print(A)\n",
    "print(A.reshape(4,5))\n",
    "print(A.reshape(4,-1).shape) # 앞 행을 참고해서 알아서 열의 수를 맞춰주는 것\n",
    "print()\n",
    "\n",
    "# 행 벡터, 열 벡터를 만들 때 다음과 같이 많이 사용한다!\n",
    "print(A.reshape(1,-1).shape) # 행 벡터\n",
    "print(A.reshape(-1,1).shape) # 2차원 열 벡터"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4, 5, 6])\n",
      "torch.Size([4, 5, 6])\n",
      "torch.Size([2, 3, 4, 5])\n",
      "torch.Size([2, 3, 4, 5])\n",
      "torch.Size([3, 4, 6])\n",
      "torch.Size([3, 4, 5])\n"
     ]
    }
   ],
   "source": [
    "x=torch.randn(2,3,4,5,6)\n",
    "print(x[1,2,:,:,:].shape)\n",
    "print(x[1,2,...].shape) # = x[1, 2, :, :, :]과 동일\n",
    "print(x[:,:,:,:,3].shape)\n",
    "print(x[...,3].shape) # = x[:, :, :, :, 3]과 동일\n",
    "print(x[1,:,:,3,:].shape)\n",
    "print(x[1,...,3,:].shape) # = x[1, :, :, 3, :]과 동일\n",
    "# :,를 ...로 대체해서 사용 가능"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 1.],\n",
      "        [1., 1.],\n",
      "        [1., 1.],\n",
      "        [0., 0.],\n",
      "        [0., 0.],\n",
      "        [0., 0.]])\n",
      "torch.Size([6, 2])\n",
      "tensor([[1., 1., 0., 0.],\n",
      "        [1., 1., 0., 0.],\n",
      "        [1., 1., 0., 0.]])\n",
      "torch.Size([3, 4])\n"
     ]
    }
   ],
   "source": [
    "A=torch.ones((3,2))\n",
    "B=torch.zeros((3,2))\n",
    "\n",
    "C=torch.vstack([A,B])\n",
    "D=torch.hstack([A,B]) # v는 0번째 차원, h는 1번째 차원에 쌓는다.\n",
    "\n",
    "print(C)\n",
    "print(C.shape)\n",
    "print(D)\n",
    "print(D.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4, 3, 4])\n",
      "torch.Size([2, 6, 4])\n",
      "torch.Size([2, 3, 8])\n"
     ]
    }
   ],
   "source": [
    "A=torch.ones((2,3,4))\n",
    "B=torch.zeros((2,3,4))\n",
    "\n",
    "# = numpy block = concatenation\n",
    "  # 각 dim을 기준으로 추가한다\n",
    "E=torch.cat([A,B], dim=0)\n",
    "print(E.shape)\n",
    "F=torch.cat([A,B], dim=1)\n",
    "print(F.shape)\n",
    "G=torch.cat([A,B], dim=2)\n",
    "print(G.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[[[[[[-0.8151],\n",
      "              [ 1.6244],\n",
      "              [ 1.1603],\n",
      "              [ 1.0319]]]],\n",
      "\n",
      "\n",
      "\n",
      "           [[[[-1.6093],\n",
      "              [-0.4293],\n",
      "              [ 1.2591],\n",
      "              [-0.4259]]]],\n",
      "\n",
      "\n",
      "\n",
      "           [[[[ 0.4049],\n",
      "              [-0.0873],\n",
      "              [ 1.0041],\n",
      "              [-0.5879]]]]]]]])\n",
      "\n",
      "torch.Size([1, 1, 1, 3, 1, 1, 4, 1])\n",
      "torch.Size([3, 4])\n"
     ]
    }
   ],
   "source": [
    "A = torch.randn(1,1,1,3,1,1,4,1)\n",
    "print(A)\n",
    "print()\n",
    "print(A.shape)\n",
    "print(A.squeeze().shape)\n",
    "# 해당 tensor에서 shape 1은 의미가 없으니까 squeeze로 1인 차원을 제거해주는 것\n",
    "  # input data 차원에 맞춰야하는 경우, 사용 가능하다!\n",
    "# 보통 인덱스 부여해서 해준다 > 0이나 -1 처럼 가장 바깥 거나 안쪽거는 쓸모없으니까 제거해주는 용도"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 3, 4])\n",
      "torch.Size([3, 1, 4])\n",
      "torch.Size([3, 4, 1])\n"
     ]
    }
   ],
   "source": [
    "A = torch.randn(3,4)\n",
    "print(A.unsqueeze(dim=0).shape) # 1인 차원을 추가해주는 것!\n",
    "# = A.reshape(1,3,4), shape도 동일하고 내부 값들도 모두 동일하다!\n",
    "print(A.unsqueeze(dim=1).shape) # = A.reshape(3,1,4)\n",
    "print(A.unsqueeze(dim=2).shape) # = A.reshape(3,4,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[1., 1., 1., 1.],\n",
      "         [1., 1., 1., 1.],\n",
      "         [1., 1., 1., 1.]],\n",
      "\n",
      "        [[0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0.]]])\n",
      "torch.Size([2, 3, 4])\n"
     ]
    }
   ],
   "source": [
    "# unsqueeze 예시!\n",
    "A=torch.ones(3,4)\n",
    "B=torch.zeros(3,4)\n",
    "# 해당 3x4 tensor를 가지고, 겹쳐 2x3x4 (3x4 tensor, 2개 차원)을 만들고 싶다!\n",
    "  # > torch.cat 등 다른 것들은 6x4 or 3x8 등 붙이는 것만 가능\n",
    "A=A.unsqueeze(dim=0)\n",
    "B=B.unsqueeze(dim=0) # (1,3,4)로 차원을 늘린 후\n",
    "C=torch.cat([A,B], dim=0) # 붙이기\n",
    "print(C)\n",
    "print(C.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[100,   2],\n",
      "        [  3,   4]])\n",
      "tensor([[1, 2],\n",
      "        [3, 4]])\n"
     ]
    }
   ],
   "source": [
    "A=torch.tensor([[1,2],[3,4]])\n",
    "B=A.clone() # 그냥 B=A인 경우, 주소까지 같이 보내는 것\n",
    "# 만약 A의 값만 사용하고 싶다면, clone 사용!\n",
    "B[0,0]=100\n",
    "\n",
    "print(B)\n",
    "print(A) # A는 안 변한 것 확인 !"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[1, 2],\n",
      "         [3, 4]],\n",
      "\n",
      "        [[5, 6],\n",
      "         [7, 8]]])\n",
      "tensor([1, 2, 3, 4, 5, 6, 7, 8])\n",
      "tensor([[1, 2, 3, 4],\n",
      "        [5, 6, 7, 8]])\n"
     ]
    }
   ],
   "source": [
    "X = torch.tensor([[[1,2],[3,4]],[[5,6],[7,8]]])\n",
    "print(X)\n",
    "print(torch.flatten(X, start_dim=0)) # default\n",
    "print(torch.flatten(X, start_dim=1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"image/flatten.jpeg\" width=\"300\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# @ 추가 설명"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([5, 10])\n",
      "torch.Size([32, 5, 10])\n"
     ]
    }
   ],
   "source": [
    "A=torch.randn(5,7)\n",
    "B=torch.randn(7,10)\n",
    "C=A@B\n",
    "print(C.shape) # 5x7@7x10 = 5x10\n",
    "\n",
    "A=torch.randn(32,5,7)\n",
    "B=torch.randn(32,7,10)\n",
    "C=A@B # 5x7@7x10 계산을 32개에 대해 각각 계산한다\n",
    "print(C.shape) # 5x10 행렬이 32차원으로 나타남"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.3088, -1.8175,  1.7420,  0.8383, -1.0566],\n",
      "        [ 0.0231, -2.3690, -0.5960,  0.5770, -0.8623]])\n",
      "tensor([[-0.3088, -1.8175,  1.7420,  0.8383, -1.0566, -0.3088, -1.8175,  1.7420,\n",
      "          0.8383, -1.0566],\n",
      "        [ 0.0231, -2.3690, -0.5960,  0.5770, -0.8623,  0.0231, -2.3690, -0.5960,\n",
      "          0.5770, -0.8623],\n",
      "        [-0.3088, -1.8175,  1.7420,  0.8383, -1.0566, -0.3088, -1.8175,  1.7420,\n",
      "          0.8383, -1.0566],\n",
      "        [ 0.0231, -2.3690, -0.5960,  0.5770, -0.8623,  0.0231, -2.3690, -0.5960,\n",
      "          0.5770, -0.8623],\n",
      "        [-0.3088, -1.8175,  1.7420,  0.8383, -1.0566, -0.3088, -1.8175,  1.7420,\n",
      "          0.8383, -1.0566],\n",
      "        [ 0.0231, -2.3690, -0.5960,  0.5770, -0.8623,  0.0231, -2.3690, -0.5960,\n",
      "          0.5770, -0.8623]])\n"
     ]
    }
   ],
   "source": [
    "B=torch.randn(2,5)\n",
    "print(B)\n",
    "print(B.repeat(3,2)) # 2x5 행렬을 3차원으로 반복해서 만든다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 5, 10])\n",
      "torch.Size([32, 5, 10])\n",
      "tensor([[[ True,  True,  True,  ...,  True,  True,  True],\n",
      "         [ True,  True,  True,  ...,  True,  True,  True],\n",
      "         [ True,  True,  True,  ...,  True, False,  True],\n",
      "         [ True,  True,  True,  ...,  True, False,  True],\n",
      "         [ True,  True,  True,  ...,  True,  True,  True]],\n",
      "\n",
      "        [[ True,  True,  True,  ...,  True,  True,  True],\n",
      "         [ True,  True,  True,  ...,  True,  True,  True],\n",
      "         [ True,  True,  True,  ...,  True,  True,  True],\n",
      "         [ True,  True,  True,  ...,  True, False,  True],\n",
      "         [ True,  True,  True,  ...,  True,  True,  True]],\n",
      "\n",
      "        [[ True,  True,  True,  ...,  True,  True, False],\n",
      "         [ True,  True,  True,  ...,  True, False, False],\n",
      "         [ True,  True,  True,  ...,  True,  True,  True],\n",
      "         [ True,  True,  True,  ...,  True,  True, False],\n",
      "         [ True,  True,  True,  ...,  True,  True,  True]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ True,  True,  True,  ...,  True,  True,  True],\n",
      "         [ True,  True,  True,  ...,  True, False,  True],\n",
      "         [ True,  True,  True,  ...,  True, False, False],\n",
      "         [ True,  True,  True,  ...,  True,  True,  True],\n",
      "         [ True,  True,  True,  ...,  True,  True,  True]],\n",
      "\n",
      "        [[ True,  True,  True,  ...,  True,  True,  True],\n",
      "         [ True,  True,  True,  ...,  True,  True,  True],\n",
      "         [ True,  True,  True,  ...,  True,  True, False],\n",
      "         [ True,  True,  True,  ...,  True,  True,  True],\n",
      "         [ True,  True,  True,  ...,  True, False, False]],\n",
      "\n",
      "        [[ True,  True,  True,  ...,  True, False,  True],\n",
      "         [ True,  True,  True,  ...,  True,  True,  True],\n",
      "         [ True,  True,  True,  ...,  True,  True, False],\n",
      "         [ True,  True,  True,  ...,  True,  True,  True],\n",
      "         [ True,  True,  True,  ...,  True,  True, False]]])\n"
     ]
    }
   ],
   "source": [
    "A=torch.randn(32,5,7)\n",
    "B=torch.randn(7,10)\n",
    "\n",
    "# shape 맞춰 계산\n",
    "C=A@B.repeat(32,1,1) # B.repeat(32,1,1) = 동일한 7x10 행렬을 32개 가진 tensor B\n",
    "print(C.shape)\n",
    "\n",
    "# repeat 없이 그냥 계산 = shape 안 맞음\n",
    "D=A@B\n",
    "print(D.shape)\n",
    "\n",
    "print(C == D) # 동일한 결과 값이어야 하는 거 아닌가..? 왜 다른 것도 있지?\n",
    "# print((C-D).abs().max()) > 그렇게 크게 차이나지 않는다 ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[ 0.0460, -0.2198],\n",
      "         [ 0.0799, -0.3820],\n",
      "         [-0.0289,  0.1384]],\n",
      "\n",
      "        [[-0.2470,  1.1811],\n",
      "         [-0.0217,  0.1037],\n",
      "         [-0.1246,  0.5959]],\n",
      "\n",
      "        [[ 0.1126, -0.5382],\n",
      "         [-0.0131,  0.0627],\n",
      "         [-0.1261,  0.6031]]])\n",
      "tensor([[[ 0.0460, -0.2198],\n",
      "         [ 0.0799, -0.3820],\n",
      "         [-0.0289,  0.1384]],\n",
      "\n",
      "        [[-0.2470,  1.1811],\n",
      "         [-0.0217,  0.1037],\n",
      "         [-0.1246,  0.5959]],\n",
      "\n",
      "        [[ 0.1126, -0.5382],\n",
      "         [-0.0131,  0.0627],\n",
      "         [-0.1261,  0.6031]]])\n",
      "tensor([[[True, True],\n",
      "         [True, True],\n",
      "         [True, True]],\n",
      "\n",
      "        [[True, True],\n",
      "         [True, True],\n",
      "         [True, True]],\n",
      "\n",
      "        [[True, True],\n",
      "         [True, True],\n",
      "         [True, True]]])\n"
     ]
    }
   ],
   "source": [
    "A=torch.randn(3,3,1)\n",
    "B=torch.randn(1,2)\n",
    "\n",
    "C=A@B.repeat(3,1,1)\n",
    "print(C)\n",
    "\n",
    "D=A@B\n",
    "print(D)\n",
    "\n",
    "print(C == D) # 얜 또 맞는다?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 1, 6, 6])\n",
      "\n",
      "tensor([[0.4851, 0.0917, 0.9757],\n",
      "        [0.6380, 0.3267, 0.1177]])\n",
      "tensor([[[[0.4851, 0.0917, 0.9757, 0.4851, 0.0917, 0.9757],\n",
      "          [0.6380, 0.3267, 0.1177, 0.6380, 0.3267, 0.1177],\n",
      "          [0.4851, 0.0917, 0.9757, 0.4851, 0.0917, 0.9757],\n",
      "          [0.6380, 0.3267, 0.1177, 0.6380, 0.3267, 0.1177],\n",
      "          [0.4851, 0.0917, 0.9757, 0.4851, 0.0917, 0.9757],\n",
      "          [0.6380, 0.3267, 0.1177, 0.6380, 0.3267, 0.1177]]],\n",
      "\n",
      "\n",
      "        [[[0.4851, 0.0917, 0.9757, 0.4851, 0.0917, 0.9757],\n",
      "          [0.6380, 0.3267, 0.1177, 0.6380, 0.3267, 0.1177],\n",
      "          [0.4851, 0.0917, 0.9757, 0.4851, 0.0917, 0.9757],\n",
      "          [0.6380, 0.3267, 0.1177, 0.6380, 0.3267, 0.1177],\n",
      "          [0.4851, 0.0917, 0.9757, 0.4851, 0.0917, 0.9757],\n",
      "          [0.6380, 0.3267, 0.1177, 0.6380, 0.3267, 0.1177]]],\n",
      "\n",
      "\n",
      "        [[[0.4851, 0.0917, 0.9757, 0.4851, 0.0917, 0.9757],\n",
      "          [0.6380, 0.3267, 0.1177, 0.6380, 0.3267, 0.1177],\n",
      "          [0.4851, 0.0917, 0.9757, 0.4851, 0.0917, 0.9757],\n",
      "          [0.6380, 0.3267, 0.1177, 0.6380, 0.3267, 0.1177],\n",
      "          [0.4851, 0.0917, 0.9757, 0.4851, 0.0917, 0.9757],\n",
      "          [0.6380, 0.3267, 0.1177, 0.6380, 0.3267, 0.1177]]]])\n"
     ]
    }
   ],
   "source": [
    "A = torch.rand(2,3)\n",
    "A_repeat=A.repeat(3,1,3,2)\n",
    "print(A_repeat.shape)\n",
    "print()\n",
    "\n",
    "print(A)\n",
    "print(A_repeat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 부연설명\n",
    "\n",
    "<img src=\"image/tensor_indexing.jpeg\" width=\"450\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# numpy와 torch 호환가능하다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'torch.Tensor'>\n",
      "<class 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "a=np.array([1,2,3])\n",
    "b=torch.tensor([1,2,3])\n",
    "A=torch.tensor(a) # A=torch.from_numpy(a)\n",
    "B=b.numpy() # B=np.array(b)\n",
    "print(type(A))\n",
    "print(type(B))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DL",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
