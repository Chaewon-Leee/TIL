{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Autograd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.tensor([1.], requires_grad=True) # requires_grad : 미분할 것이라고 미리 표시해두는 것\n",
    "# 그래서 tensor 값이 소수로 들어가야 한다!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "x = torch.tensor([1.])\n",
    "print(x.requires_grad)\n",
    "x.requires_grad=True # 이후에 붙여줄 수도 있음\n",
    "print(x.requires_grad)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## detach()와 torch.no_grad"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ".requires_grad = False 대신 사용 가능한 것들!\n",
    "- detach() & torch.no_grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'detach' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/Users/lee/Desktop/workspace/git/TIL/PYTORCH/Ch.1/Autograd.ipynb 셀 6\u001b[0m line \u001b[0;36m2\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/lee/Desktop/workspace/git/TIL/PYTORCH/Ch.1/Autograd.ipynb#X26sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m x \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mtensor([\u001b[39m1.\u001b[39m], requires_grad\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/lee/Desktop/workspace/git/TIL/PYTORCH/Ch.1/Autograd.ipynb#X26sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m x \u001b[39m=\u001b[39m x,detach()\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/lee/Desktop/workspace/git/TIL/PYTORCH/Ch.1/Autograd.ipynb#X26sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m \u001b[39mprint\u001b[39m(x\u001b[39m.\u001b[39mrequires_grad)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'detach' is not defined"
     ]
    }
   ],
   "source": [
    "x = torch.tensor([1.], requires_grad=True)\n",
    "x = x,detach() # 아마 설치 버전이 달라 안되는 것 같다\n",
    "print(x.requires_grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "tensor([1.])\n",
      "True\n",
      "tensor([1.], grad_fn=<PowBackward0>)\n"
     ]
    }
   ],
   "source": [
    "x = torch.tensor([1.], requires_grad=True)\n",
    "with torch.no_grad():\n",
    "  print(x.requires_grad)\n",
    "  y=x**2\n",
    "  print(y) # grad_fn을 기억하지 않는다!\n",
    "print(x.requires_grad)\n",
    "y=x**2\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "detach() vs torch.no_grad\n",
    "- detach() : \"requires_grad = False\"와 동일하게 아에 requires_grad를 떼버리는 것\n",
    "- no_grad : 해당 순간에만 grad_fn을 기억하지 않도록 하는 것 > requires_grad는 여전히 True이다!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "언제 사용하느냐?\n",
    "1. transfer learning\n",
    "- 기존의 weights를 유지하면서, 일부분을 학습시키고 싶을 때!\n",
    "  - 만약 강아지 100종에 대해서 pretrained된 모델을 사용하고, 나는 10종에 대해서만 한정해서 분류하고 싶다!\n",
    "  - 해당 가중치는 유지하되 (freeze), 마지막 분류 단계 부분만 재학습하고 싶다\n",
    "  - 이때 x.requires_grad = False를 취해 해당 부분은 업데이트가 되지 않도록 막아두는 것\n",
    "- 보통 detach() 사용\n",
    "1. 모델 테스트 단계\n",
    "- 불필요하게 메모리를 쓸 일이 없기 때문에 저장하지 않도록 하는 것\n",
    "- 보통 no_grad 사용"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 미분"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1.], grad_fn=<PowBackward0>)\n",
      "\n",
      "None\n",
      "tensor([2.])\n"
     ]
    }
   ],
   "source": [
    "x = torch.tensor([1.], requires_grad=True)\n",
    "y=x**2\n",
    "print(y) # PowBackward0 추가되어 있음\n",
    "print()\n",
    "\n",
    "print(x.grad) # 미분한 값은 grad에 있다 !\n",
    "y.backward() # y에 대해 x 미분\n",
    "print(x.grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0)\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "element 0 of tensors does not require grad and does not have a grad_fn",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m/Users/lee/Desktop/workspace/git/TIL/PYTORCH/Ch.1/Autograd.ipynb 셀 13\u001b[0m line \u001b[0;36m4\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/lee/Desktop/workspace/git/TIL/PYTORCH/Ch.1/Autograd.ipynb#X15sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m y\u001b[39m=\u001b[39mx\u001b[39m.\u001b[39margmax()\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/lee/Desktop/workspace/git/TIL/PYTORCH/Ch.1/Autograd.ipynb#X15sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m \u001b[39mprint\u001b[39m(y) \u001b[39m# PowBackward0 추가 X > 미분이 불가능하므로!\u001b[39;00m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/lee/Desktop/workspace/git/TIL/PYTORCH/Ch.1/Autograd.ipynb#X15sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m y\u001b[39m.\u001b[39;49mbackward() \u001b[39m# 에러\u001b[39;00m\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/DL/lib/python3.8/site-packages/torch/_tensor.py:488\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    478\u001b[0m \u001b[39mif\u001b[39;00m has_torch_function_unary(\u001b[39mself\u001b[39m):\n\u001b[1;32m    479\u001b[0m     \u001b[39mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    480\u001b[0m         Tensor\u001b[39m.\u001b[39mbackward,\n\u001b[1;32m    481\u001b[0m         (\u001b[39mself\u001b[39m,),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    486\u001b[0m         inputs\u001b[39m=\u001b[39minputs,\n\u001b[1;32m    487\u001b[0m     )\n\u001b[0;32m--> 488\u001b[0m torch\u001b[39m.\u001b[39;49mautograd\u001b[39m.\u001b[39;49mbackward(\n\u001b[1;32m    489\u001b[0m     \u001b[39mself\u001b[39;49m, gradient, retain_graph, create_graph, inputs\u001b[39m=\u001b[39;49minputs\n\u001b[1;32m    490\u001b[0m )\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/DL/lib/python3.8/site-packages/torch/autograd/__init__.py:197\u001b[0m, in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    192\u001b[0m     retain_graph \u001b[39m=\u001b[39m create_graph\n\u001b[1;32m    194\u001b[0m \u001b[39m# The reason we repeat same the comment below is that\u001b[39;00m\n\u001b[1;32m    195\u001b[0m \u001b[39m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[1;32m    196\u001b[0m \u001b[39m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[0;32m--> 197\u001b[0m Variable\u001b[39m.\u001b[39;49m_execution_engine\u001b[39m.\u001b[39;49mrun_backward(  \u001b[39m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[1;32m    198\u001b[0m     tensors, grad_tensors_, retain_graph, create_graph, inputs,\n\u001b[1;32m    199\u001b[0m     allow_unreachable\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m, accumulate_grad\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m)\n",
      "\u001b[0;31mRuntimeError\u001b[0m: element 0 of tensors does not require grad and does not have a grad_fn"
     ]
    }
   ],
   "source": [
    "x = torch.tensor([1.], requires_grad=True)\n",
    "y=x.argmax()\n",
    "print(y) # PowBackward0 추가 X > 미분이 불가능하므로!\n",
    "y.backward() # 에러"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([3.], grad_fn=<MulBackward0>)\n",
      "tensor([6.])\n"
     ]
    }
   ],
   "source": [
    "x = torch.tensor([1.], requires_grad=True)\n",
    "y=x**2\n",
    "z = 3*y\n",
    "print(z) # MulBackward0 추가되어 있음 > 연산방식에 대해 기억을 하고 있다\n",
    "z.backward() # requires_grad를 찾아 미분을 한다\n",
    "# 즉, y에는 requires_grad가 없고 x에만 있으므로, dz/dy >> dy/dx 순인 chain rule를 활용해서 dz/dx를 값을 얻을 수 있는 것\n",
    "print(x.grad)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "grad_fn 추가"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([12.], grad_fn=<MulBackward0>)\n"
     ]
    }
   ],
   "source": [
    "x = torch.tensor([1.], requires_grad=True)\n",
    "y=(3*x**2 +1)*3\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "곱셈, 제곱셈, 더하기 연산 다 했지만, grad_fn이 기억하는 것은 마지막 연산 계산 > 모든 연산 계산 방식을 나타내지는 않는다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/yr/33_dxfw93nzc66j2xmmvkxnw0000gn/T/ipykernel_90017/1324337507.py:1: UserWarning: The .grad attribute of a Tensor that is not a leaf Tensor is being accessed. Its .grad attribute won't be populated during autograd.backward(). If you indeed want the .grad field to be populated for a non-leaf Tensor, use .retain_grad() on the non-leaf Tensor. If you access the non-leaf Tensor by mistake, make sure you access the leaf Tensor instead. See github.com/pytorch/pytorch/pull/30531 for more informations. (Triggered internally at /Users/runner/work/_temp/anaconda/conda-bld/pytorch_1670525474122/work/build/aten/src/ATen/core/TensorBody.h:485.)\n",
      "  print(y.grad)\n"
     ]
    }
   ],
   "source": [
    "print(y.grad) # requires_grad가 없으므로, 값이 없다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([3.])\n"
     ]
    }
   ],
   "source": [
    "x = torch.tensor([1.], requires_grad=True)\n",
    "y=x**2\n",
    "z = 3*y\n",
    "\n",
    "y.retain_grad() # 중간 stem에 대해서 미분하겠다고 변경하는 것\n",
    "\n",
    "z.backward() # z를 y에 대해서 미분하겠다\n",
    "# y는 1**2로, 1 값을 가지고 있으니까 z 미분한 것에 대해 y 값을 넣어 y.grad에 저장!\n",
    "print(y.grad)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "y.requires_grad=True 는 불가능! 태초부터 시작해야만 (=tensor) requires_grad 가 가능하다\n",
    "- 또한, z식을 작성하기 전 requires_grad=True를 해야만 backward()가 가능함!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "element 0 of tensors does not require grad and does not have a grad_fn",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m/Users/lee/Desktop/workspace/git/TIL/PYTORCH/Ch.1/Autograd.ipynb 셀 10\u001b[0m line \u001b[0;36m5\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/lee/Desktop/workspace/git/TIL/PYTORCH/Ch.1/Autograd.ipynb#X12sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m y\u001b[39m.\u001b[39mrequires_grad\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/lee/Desktop/workspace/git/TIL/PYTORCH/Ch.1/Autograd.ipynb#X12sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m \u001b[39mprint\u001b[39m(y\u001b[39m.\u001b[39mrequires_grad)\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/lee/Desktop/workspace/git/TIL/PYTORCH/Ch.1/Autograd.ipynb#X12sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m z\u001b[39m.\u001b[39;49mbackward()\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/DL/lib/python3.8/site-packages/torch/_tensor.py:488\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    478\u001b[0m \u001b[39mif\u001b[39;00m has_torch_function_unary(\u001b[39mself\u001b[39m):\n\u001b[1;32m    479\u001b[0m     \u001b[39mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    480\u001b[0m         Tensor\u001b[39m.\u001b[39mbackward,\n\u001b[1;32m    481\u001b[0m         (\u001b[39mself\u001b[39m,),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    486\u001b[0m         inputs\u001b[39m=\u001b[39minputs,\n\u001b[1;32m    487\u001b[0m     )\n\u001b[0;32m--> 488\u001b[0m torch\u001b[39m.\u001b[39;49mautograd\u001b[39m.\u001b[39;49mbackward(\n\u001b[1;32m    489\u001b[0m     \u001b[39mself\u001b[39;49m, gradient, retain_graph, create_graph, inputs\u001b[39m=\u001b[39;49minputs\n\u001b[1;32m    490\u001b[0m )\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/DL/lib/python3.8/site-packages/torch/autograd/__init__.py:197\u001b[0m, in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    192\u001b[0m     retain_graph \u001b[39m=\u001b[39m create_graph\n\u001b[1;32m    194\u001b[0m \u001b[39m# The reason we repeat same the comment below is that\u001b[39;00m\n\u001b[1;32m    195\u001b[0m \u001b[39m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[1;32m    196\u001b[0m \u001b[39m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[0;32m--> 197\u001b[0m Variable\u001b[39m.\u001b[39;49m_execution_engine\u001b[39m.\u001b[39;49mrun_backward(  \u001b[39m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[1;32m    198\u001b[0m     tensors, grad_tensors_, retain_graph, create_graph, inputs,\n\u001b[1;32m    199\u001b[0m     allow_unreachable\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m, accumulate_grad\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m)\n",
      "\u001b[0;31mRuntimeError\u001b[0m: element 0 of tensors does not require grad and does not have a grad_fn"
     ]
    }
   ],
   "source": [
    "y=torch.tensor([1.])\n",
    "z = 3*y\n",
    "y.requires_grad=True\n",
    "print(y.requires_grad) # True이지만, 이미 z를 정의한 이후로 시도했으므로 에러 발생\n",
    "z.backward()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 편미분"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([4.])\n",
      "tensor([2.])\n"
     ]
    }
   ],
   "source": [
    "x=torch.tensor([1.], requires_grad=True)\n",
    "y=torch.tensor([1.], requires_grad=True)\n",
    "z = 2*x**2 + y**2\n",
    "z.backward()\n",
    "\n",
    "# z에 대해서 각각 편미분하고, 대입한 값이 들어가 있다\n",
    "print(x.grad)\n",
    "print(y.grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(14., grad_fn=<SumBackward0>)\n",
      "tensor([2., 4., 6.])\n"
     ]
    }
   ],
   "source": [
    "x=torch.tensor([1., 2., 3.], requires_grad=True)\n",
    "y=torch.sum(x**2) # x1**2 + x2**2 + x3**2\n",
    "print(y)\n",
    "\n",
    "y.backward()\n",
    "print(x.grad) # 스칼라를 벡터로 미분한 것"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## make_dot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torchviz in /Users/lee/opt/anaconda3/envs/DL/lib/python3.8/site-packages (0.0.2)\n",
      "Requirement already satisfied: graphviz in /Users/lee/opt/anaconda3/envs/DL/lib/python3.8/site-packages (from torchviz) (0.20.1)\n",
      "Requirement already satisfied: torch in /Users/lee/opt/anaconda3/envs/DL/lib/python3.8/site-packages (from torchviz) (1.13.1)\n",
      "Requirement already satisfied: typing_extensions in /Users/lee/opt/anaconda3/envs/DL/lib/python3.8/site-packages (from torch->torchviz) (4.4.0)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.0.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m23.3.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install torchviz\n",
    "from torchviz import make_dot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "ename": "ExecutableNotFound",
     "evalue": "failed to execute PosixPath('dot'), make sure the Graphviz executables are on your systems' PATH",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "File \u001b[0;32m~/opt/anaconda3/envs/DL/lib/python3.8/site-packages/graphviz/backend/execute.py:79\u001b[0m, in \u001b[0;36mrun_check\u001b[0;34m(cmd, input_lines, encoding, quiet, **kwargs)\u001b[0m\n\u001b[1;32m     78\u001b[0m         kwargs[\u001b[39m'\u001b[39m\u001b[39mstdout\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m kwargs[\u001b[39m'\u001b[39m\u001b[39mstderr\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m subprocess\u001b[39m.\u001b[39mPIPE\n\u001b[0;32m---> 79\u001b[0m     proc \u001b[39m=\u001b[39m _run_input_lines(cmd, input_lines, kwargs\u001b[39m=\u001b[39;49mkwargs)\n\u001b[1;32m     80\u001b[0m \u001b[39melse\u001b[39;00m:\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/DL/lib/python3.8/site-packages/graphviz/backend/execute.py:99\u001b[0m, in \u001b[0;36m_run_input_lines\u001b[0;34m(cmd, input_lines, kwargs)\u001b[0m\n\u001b[1;32m     98\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_run_input_lines\u001b[39m(cmd, input_lines, \u001b[39m*\u001b[39m, kwargs):\n\u001b[0;32m---> 99\u001b[0m     popen \u001b[39m=\u001b[39m subprocess\u001b[39m.\u001b[39;49mPopen(cmd, stdin\u001b[39m=\u001b[39;49msubprocess\u001b[39m.\u001b[39;49mPIPE, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    101\u001b[0m     stdin_write \u001b[39m=\u001b[39m popen\u001b[39m.\u001b[39mstdin\u001b[39m.\u001b[39mwrite\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/DL/lib/python3.8/subprocess.py:858\u001b[0m, in \u001b[0;36mPopen.__init__\u001b[0;34m(self, args, bufsize, executable, stdin, stdout, stderr, preexec_fn, close_fds, shell, cwd, env, universal_newlines, startupinfo, creationflags, restore_signals, start_new_session, pass_fds, encoding, errors, text)\u001b[0m\n\u001b[1;32m    855\u001b[0m             \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstderr \u001b[39m=\u001b[39m io\u001b[39m.\u001b[39mTextIOWrapper(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstderr,\n\u001b[1;32m    856\u001b[0m                     encoding\u001b[39m=\u001b[39mencoding, errors\u001b[39m=\u001b[39merrors)\n\u001b[0;32m--> 858\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_execute_child(args, executable, preexec_fn, close_fds,\n\u001b[1;32m    859\u001b[0m                         pass_fds, cwd, env,\n\u001b[1;32m    860\u001b[0m                         startupinfo, creationflags, shell,\n\u001b[1;32m    861\u001b[0m                         p2cread, p2cwrite,\n\u001b[1;32m    862\u001b[0m                         c2pread, c2pwrite,\n\u001b[1;32m    863\u001b[0m                         errread, errwrite,\n\u001b[1;32m    864\u001b[0m                         restore_signals, start_new_session)\n\u001b[1;32m    865\u001b[0m \u001b[39mexcept\u001b[39;00m:\n\u001b[1;32m    866\u001b[0m     \u001b[39m# Cleanup if the child failed starting.\u001b[39;00m\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/DL/lib/python3.8/subprocess.py:1704\u001b[0m, in \u001b[0;36mPopen._execute_child\u001b[0;34m(self, args, executable, preexec_fn, close_fds, pass_fds, cwd, env, startupinfo, creationflags, shell, p2cread, p2cwrite, c2pread, c2pwrite, errread, errwrite, restore_signals, start_new_session)\u001b[0m\n\u001b[1;32m   1703\u001b[0m         err_msg \u001b[39m=\u001b[39m os\u001b[39m.\u001b[39mstrerror(errno_num)\n\u001b[0;32m-> 1704\u001b[0m     \u001b[39mraise\u001b[39;00m child_exception_type(errno_num, err_msg, err_filename)\n\u001b[1;32m   1705\u001b[0m \u001b[39mraise\u001b[39;00m child_exception_type(err_msg)\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: PosixPath('dot')",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mExecutableNotFound\u001b[0m                        Traceback (most recent call last)",
      "File \u001b[0;32m~/opt/anaconda3/envs/DL/lib/python3.8/site-packages/IPython/core/formatters.py:972\u001b[0m, in \u001b[0;36mMimeBundleFormatter.__call__\u001b[0;34m(self, obj, include, exclude)\u001b[0m\n\u001b[1;32m    969\u001b[0m     method \u001b[39m=\u001b[39m get_real_method(obj, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mprint_method)\n\u001b[1;32m    971\u001b[0m     \u001b[39mif\u001b[39;00m method \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m--> 972\u001b[0m         \u001b[39mreturn\u001b[39;00m method(include\u001b[39m=\u001b[39;49minclude, exclude\u001b[39m=\u001b[39;49mexclude)\n\u001b[1;32m    973\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m    974\u001b[0m \u001b[39melse\u001b[39;00m:\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/DL/lib/python3.8/site-packages/graphviz/jupyter_integration.py:98\u001b[0m, in \u001b[0;36mJupyterIntegration._repr_mimebundle_\u001b[0;34m(self, include, exclude, **_)\u001b[0m\n\u001b[1;32m     96\u001b[0m include \u001b[39m=\u001b[39m \u001b[39mset\u001b[39m(include) \u001b[39mif\u001b[39;00m include \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39melse\u001b[39;00m {\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jupyter_mimetype}\n\u001b[1;32m     97\u001b[0m include \u001b[39m-\u001b[39m\u001b[39m=\u001b[39m \u001b[39mset\u001b[39m(exclude \u001b[39mor\u001b[39;00m [])\n\u001b[0;32m---> 98\u001b[0m \u001b[39mreturn\u001b[39;00m {mimetype: \u001b[39mgetattr\u001b[39m(\u001b[39mself\u001b[39m, method_name)()\n\u001b[1;32m     99\u001b[0m         \u001b[39mfor\u001b[39;00m mimetype, method_name \u001b[39min\u001b[39;00m MIME_TYPES\u001b[39m.\u001b[39mitems()\n\u001b[1;32m    100\u001b[0m         \u001b[39mif\u001b[39;00m mimetype \u001b[39min\u001b[39;00m include}\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/DL/lib/python3.8/site-packages/graphviz/jupyter_integration.py:98\u001b[0m, in \u001b[0;36m<dictcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     96\u001b[0m include \u001b[39m=\u001b[39m \u001b[39mset\u001b[39m(include) \u001b[39mif\u001b[39;00m include \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39melse\u001b[39;00m {\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jupyter_mimetype}\n\u001b[1;32m     97\u001b[0m include \u001b[39m-\u001b[39m\u001b[39m=\u001b[39m \u001b[39mset\u001b[39m(exclude \u001b[39mor\u001b[39;00m [])\n\u001b[0;32m---> 98\u001b[0m \u001b[39mreturn\u001b[39;00m {mimetype: \u001b[39mgetattr\u001b[39;49m(\u001b[39mself\u001b[39;49m, method_name)()\n\u001b[1;32m     99\u001b[0m         \u001b[39mfor\u001b[39;00m mimetype, method_name \u001b[39min\u001b[39;00m MIME_TYPES\u001b[39m.\u001b[39mitems()\n\u001b[1;32m    100\u001b[0m         \u001b[39mif\u001b[39;00m mimetype \u001b[39min\u001b[39;00m include}\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/DL/lib/python3.8/site-packages/graphviz/jupyter_integration.py:112\u001b[0m, in \u001b[0;36mJupyterIntegration._repr_image_svg_xml\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    110\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_repr_image_svg_xml\u001b[39m(\u001b[39mself\u001b[39m) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m \u001b[39mstr\u001b[39m:\n\u001b[1;32m    111\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Return the rendered graph as SVG string.\"\"\"\u001b[39;00m\n\u001b[0;32m--> 112\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mpipe(\u001b[39mformat\u001b[39;49m\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39msvg\u001b[39;49m\u001b[39m'\u001b[39;49m, encoding\u001b[39m=\u001b[39;49mSVG_ENCODING)\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/DL/lib/python3.8/site-packages/graphviz/piping.py:104\u001b[0m, in \u001b[0;36mPipe.pipe\u001b[0;34m(self, format, renderer, formatter, neato_no_op, quiet, engine, encoding)\u001b[0m\n\u001b[1;32m     55\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mpipe\u001b[39m(\u001b[39mself\u001b[39m,\n\u001b[1;32m     56\u001b[0m          \u001b[39mformat\u001b[39m: typing\u001b[39m.\u001b[39mOptional[\u001b[39mstr\u001b[39m] \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m,\n\u001b[1;32m     57\u001b[0m          renderer: typing\u001b[39m.\u001b[39mOptional[\u001b[39mstr\u001b[39m] \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     61\u001b[0m          engine: typing\u001b[39m.\u001b[39mOptional[\u001b[39mstr\u001b[39m] \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m,\n\u001b[1;32m     62\u001b[0m          encoding: typing\u001b[39m.\u001b[39mOptional[\u001b[39mstr\u001b[39m] \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m typing\u001b[39m.\u001b[39mUnion[\u001b[39mbytes\u001b[39m, \u001b[39mstr\u001b[39m]:\n\u001b[1;32m     63\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Return the source piped through the Graphviz layout command.\u001b[39;00m\n\u001b[1;32m     64\u001b[0m \n\u001b[1;32m     65\u001b[0m \u001b[39m    Args:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    102\u001b[0m \u001b[39m        '<?xml version='\u001b[39;00m\n\u001b[1;32m    103\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 104\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_pipe_legacy(\u001b[39mformat\u001b[39;49m,\n\u001b[1;32m    105\u001b[0m                              renderer\u001b[39m=\u001b[39;49mrenderer,\n\u001b[1;32m    106\u001b[0m                              formatter\u001b[39m=\u001b[39;49mformatter,\n\u001b[1;32m    107\u001b[0m                              neato_no_op\u001b[39m=\u001b[39;49mneato_no_op,\n\u001b[1;32m    108\u001b[0m                              quiet\u001b[39m=\u001b[39;49mquiet,\n\u001b[1;32m    109\u001b[0m                              engine\u001b[39m=\u001b[39;49mengine,\n\u001b[1;32m    110\u001b[0m                              encoding\u001b[39m=\u001b[39;49mencoding)\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/DL/lib/python3.8/site-packages/graphviz/_tools.py:171\u001b[0m, in \u001b[0;36mdeprecate_positional_args.<locals>.decorator.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    162\u001b[0m     wanted \u001b[39m=\u001b[39m \u001b[39m'\u001b[39m\u001b[39m, \u001b[39m\u001b[39m'\u001b[39m\u001b[39m.\u001b[39mjoin(\u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39m{\u001b[39;00mname\u001b[39m}\u001b[39;00m\u001b[39m=\u001b[39m\u001b[39m{\u001b[39;00mvalue\u001b[39m!r}\u001b[39;00m\u001b[39m'\u001b[39m\n\u001b[1;32m    163\u001b[0m                        \u001b[39mfor\u001b[39;00m name, value \u001b[39min\u001b[39;00m deprecated\u001b[39m.\u001b[39mitems())\n\u001b[1;32m    164\u001b[0m     warnings\u001b[39m.\u001b[39mwarn(\u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39mThe signature of \u001b[39m\u001b[39m{\u001b[39;00mfunc\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m will be reduced\u001b[39m\u001b[39m'\u001b[39m\n\u001b[1;32m    165\u001b[0m                   \u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39m to \u001b[39m\u001b[39m{\u001b[39;00msupported_number\u001b[39m}\u001b[39;00m\u001b[39m positional args\u001b[39m\u001b[39m'\u001b[39m\n\u001b[1;32m    166\u001b[0m                   \u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39m \u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mlist\u001b[39m(supported)\u001b[39m}\u001b[39;00m\u001b[39m: pass \u001b[39m\u001b[39m{\u001b[39;00mwanted\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m\n\u001b[1;32m    167\u001b[0m                   \u001b[39m'\u001b[39m\u001b[39m as keyword arg(s)\u001b[39m\u001b[39m'\u001b[39m,\n\u001b[1;32m    168\u001b[0m                   stacklevel\u001b[39m=\u001b[39mstacklevel,\n\u001b[1;32m    169\u001b[0m                   category\u001b[39m=\u001b[39mcategory)\n\u001b[0;32m--> 171\u001b[0m \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/DL/lib/python3.8/site-packages/graphviz/piping.py:121\u001b[0m, in \u001b[0;36mPipe._pipe_legacy\u001b[0;34m(self, format, renderer, formatter, neato_no_op, quiet, engine, encoding)\u001b[0m\n\u001b[1;32m    112\u001b[0m \u001b[39m@_tools\u001b[39m\u001b[39m.\u001b[39mdeprecate_positional_args(supported_number\u001b[39m=\u001b[39m\u001b[39m2\u001b[39m)\n\u001b[1;32m    113\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_pipe_legacy\u001b[39m(\u001b[39mself\u001b[39m,\n\u001b[1;32m    114\u001b[0m                  \u001b[39mformat\u001b[39m: typing\u001b[39m.\u001b[39mOptional[\u001b[39mstr\u001b[39m] \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    119\u001b[0m                  engine: typing\u001b[39m.\u001b[39mOptional[\u001b[39mstr\u001b[39m] \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m,\n\u001b[1;32m    120\u001b[0m                  encoding: typing\u001b[39m.\u001b[39mOptional[\u001b[39mstr\u001b[39m] \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m typing\u001b[39m.\u001b[39mUnion[\u001b[39mbytes\u001b[39m, \u001b[39mstr\u001b[39m]:\n\u001b[0;32m--> 121\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_pipe_future(\u001b[39mformat\u001b[39;49m,\n\u001b[1;32m    122\u001b[0m                              renderer\u001b[39m=\u001b[39;49mrenderer,\n\u001b[1;32m    123\u001b[0m                              formatter\u001b[39m=\u001b[39;49mformatter,\n\u001b[1;32m    124\u001b[0m                              neato_no_op\u001b[39m=\u001b[39;49mneato_no_op,\n\u001b[1;32m    125\u001b[0m                              quiet\u001b[39m=\u001b[39;49mquiet,\n\u001b[1;32m    126\u001b[0m                              engine\u001b[39m=\u001b[39;49mengine,\n\u001b[1;32m    127\u001b[0m                              encoding\u001b[39m=\u001b[39;49mencoding)\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/DL/lib/python3.8/site-packages/graphviz/piping.py:149\u001b[0m, in \u001b[0;36mPipe._pipe_future\u001b[0;34m(self, format, renderer, formatter, neato_no_op, quiet, engine, encoding)\u001b[0m\n\u001b[1;32m    146\u001b[0m \u001b[39mif\u001b[39;00m encoding \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    147\u001b[0m     \u001b[39mif\u001b[39;00m codecs\u001b[39m.\u001b[39mlookup(encoding) \u001b[39mis\u001b[39;00m codecs\u001b[39m.\u001b[39mlookup(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mencoding):\n\u001b[1;32m    148\u001b[0m         \u001b[39m# common case: both stdin and stdout need the same encoding\u001b[39;00m\n\u001b[0;32m--> 149\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_pipe_lines_string(\u001b[39m*\u001b[39;49margs, encoding\u001b[39m=\u001b[39;49mencoding, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    150\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m    151\u001b[0m         raw \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_pipe_lines(\u001b[39m*\u001b[39margs, input_encoding\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mencoding, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/DL/lib/python3.8/site-packages/graphviz/backend/piping.py:212\u001b[0m, in \u001b[0;36mpipe_lines_string\u001b[0;34m(engine, format, input_lines, encoding, renderer, formatter, neato_no_op, quiet)\u001b[0m\n\u001b[1;32m    206\u001b[0m cmd \u001b[39m=\u001b[39m dot_command\u001b[39m.\u001b[39mcommand(engine, \u001b[39mformat\u001b[39m,\n\u001b[1;32m    207\u001b[0m                           renderer\u001b[39m=\u001b[39mrenderer,\n\u001b[1;32m    208\u001b[0m                           formatter\u001b[39m=\u001b[39mformatter,\n\u001b[1;32m    209\u001b[0m                           neato_no_op\u001b[39m=\u001b[39mneato_no_op)\n\u001b[1;32m    210\u001b[0m kwargs \u001b[39m=\u001b[39m {\u001b[39m'\u001b[39m\u001b[39minput_lines\u001b[39m\u001b[39m'\u001b[39m: input_lines, \u001b[39m'\u001b[39m\u001b[39mencoding\u001b[39m\u001b[39m'\u001b[39m: encoding}\n\u001b[0;32m--> 212\u001b[0m proc \u001b[39m=\u001b[39m execute\u001b[39m.\u001b[39;49mrun_check(cmd, capture_output\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m, quiet\u001b[39m=\u001b[39;49mquiet, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    213\u001b[0m \u001b[39mreturn\u001b[39;00m proc\u001b[39m.\u001b[39mstdout\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/DL/lib/python3.8/site-packages/graphviz/backend/execute.py:84\u001b[0m, in \u001b[0;36mrun_check\u001b[0;34m(cmd, input_lines, encoding, quiet, **kwargs)\u001b[0m\n\u001b[1;32m     82\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mOSError\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m     83\u001b[0m     \u001b[39mif\u001b[39;00m e\u001b[39m.\u001b[39merrno \u001b[39m==\u001b[39m errno\u001b[39m.\u001b[39mENOENT:\n\u001b[0;32m---> 84\u001b[0m         \u001b[39mraise\u001b[39;00m ExecutableNotFound(cmd) \u001b[39mfrom\u001b[39;00m \u001b[39me\u001b[39;00m\n\u001b[1;32m     85\u001b[0m     \u001b[39mraise\u001b[39;00m\n\u001b[1;32m     87\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m quiet \u001b[39mand\u001b[39;00m proc\u001b[39m.\u001b[39mstderr:\n",
      "\u001b[0;31mExecutableNotFound\u001b[0m: failed to execute PosixPath('dot'), make sure the Graphviz executables are on your systems' PATH"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<graphviz.graphs.Digraph at 0x7fa39829af10>"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.tensor([1.,2.], requires_grad=True)\n",
    "make_dot((x**2+1)**2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"image/make_dot.png\" width=\"150\">\n",
    "\n",
    "다음과 같이 연산 방식을 그래프로 그려준다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DL",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
